<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">

  <script>
    (function(){
        if(''){
            if (prompt('请输入密码') !== ''){
                alert('密码错误');
                history.back();
            }
        }
    })();
</script>







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="TensorFlow,ConvolutionNN,">





  <link rel="alternate" href="/atom.xml" title="When Art Meets Technology" type="application/atom+xml">






<meta name="description" content="愿你每天欢喜多于悲，孤独有人陪…   写在前面： 感受野（Receptive Field）是卷积神经网络（Convolutional Neural Network，CNNs）中最重要的概念之一，目前主流的图像识别都是在基于感受野理念来设计卷积神经网络模型架构，故你在很多经典论文中都会碰到有关感受野说明。为了更好地理解卷积神经网络结构，甚至自己设计优秀的卷积神经网络，对于感受野的理解和学习必不可少">
<meta name="keywords" content="TensorFlow,ConvolutionNN">
<meta property="og:type" content="article">
<meta property="og:title" content="一文读懂卷积神经网络感受野(Receptive Field)">
<meta property="og:url" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/index.html">
<meta property="og:site_name" content="When Art Meets Technology">
<meta property="og:description" content="愿你每天欢喜多于悲，孤独有人陪…   写在前面： 感受野（Receptive Field）是卷积神经网络（Convolutional Neural Network，CNNs）中最重要的概念之一，目前主流的图像识别都是在基于感受野理念来设计卷积神经网络模型架构，故你在很多经典论文中都会碰到有关感受野说明。为了更好地理解卷积神经网络结构，甚至自己设计优秀的卷积神经网络，对于感受野的理解和学习必不可少">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/fm_visual.jpg">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/Conv_1.png">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/Conv_2.png">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/Conv_3.png">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/Conv_4.png">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/Conv_5.png">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/Conv_RF.png">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/Conv_RF_2.png">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/RF_effective.png">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/classics.png">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/classics_2.png">
<meta property="og:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/classics_3.png">
<meta property="og:updated_time" content="2019-06-26T06:23:01.438Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="一文读懂卷积神经网络感受野(Receptive Field)">
<meta name="twitter:description" content="愿你每天欢喜多于悲，孤独有人陪…   写在前面： 感受野（Receptive Field）是卷积神经网络（Convolutional Neural Network，CNNs）中最重要的概念之一，目前主流的图像识别都是在基于感受野理念来设计卷积神经网络模型架构，故你在很多经典论文中都会碰到有关感受野说明。为了更好地理解卷积神经网络结构，甚至自己设计优秀的卷积神经网络，对于感受野的理解和学习必不可少">
<meta name="twitter:image" content="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/fm_visual.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/">






  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice")
  daovoice('init', {
      app_id: "7e6ff6a0"
    });
  daovoice('update');
  </script>

  <title>一文读懂卷积神经网络感受野(Receptive Field) | When Art Meets Technology</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  
    <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">When Art Meets Technology</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TheMusicIsLoud">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="When Art Meets Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">一文读懂卷积神经网络感受野(Receptive Field)</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-02T11:03:17+08:00">
                2018-07-02
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-06-26T14:23:01+08:00">
                2019-06-26
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Convlutional-Neural-Networks/" itemprop="url" rel="index">
                    <span itemprop="name">Convlutional Neural Networks</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/" class="leancloud_visitors" data-flag-title="一文读懂卷积神经网络感受野(Receptive Field)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读热度&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
                 <span>次</span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  5.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  22
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <center> 愿你每天欢喜多于悲，孤独有人陪… </center>

<p><strong>写在前面：</strong></p>
<p>感受野（Receptive Field）是卷积神经网络（Convolutional Neural Network，CNNs）中最重要的概念之一，目前主流的图像识别都是在基于感受野理念来设计卷积神经网络模型架构，故你在很多经典论文中都会碰到有关感受野说明。为了更好地理解卷积神经网络结构，甚至自己设计优秀的卷积神经网络，对于感受野的理解和学习必不可少。</p>
<a id="more"></a>
<h3 id="1-到底什么是感受野（Receptive-Field）？"><a href="#1-到底什么是感受野（Receptive-Field）？" class="headerlink" title="1. 到底什么是感受野（Receptive Field）？"></a>1. 到底什么是感受野（Receptive Field）？</h3><p>感受野被定义为：</p>
<p>卷积神经网络每一层输出的特征图（feature map）上的<strong>特征像素点</strong>在输入图片上映射的区域。</p>
<p>通俗点说，就是图像输出的每一个特征（feature map 上任一像素点）到底受到原始图像哪一部分的影响。</p>
<p>什么，太抽象不好理解？我们来可视化 CNN 特征图观察一下感受野：</p>
<h4 id="1-1-CNN-Feature-Map-Visualization"><a href="#1-1-CNN-Feature-Map-Visualization" class="headerlink" title="1.1 CNN Feature Map  Visualization"></a>1.1 CNN Feature Map  Visualization</h4><p>为了更容易理解，我们将 feature map 从二维简化到一维。</p>
<p>下面是一个三层结构的神经卷积神经网络，每一层采用尺寸（kernel size）为：<strong>3 × 3</strong>，步长（stride）为：<strong>1 </strong>，不适用填充的过滤器。</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./fm_visual.jpg" alt="avatar"></p>
<p>你可以将其看成是图像 feature map 一条边界上卷积核的移动过程。</p>
<p>假设我们在一个 <strong>7 × 7</strong> 的输入图像像素矩阵（也可以看作一个 feature map）上进行卷积，一条边界（包含 7 个像素点）上经过上述卷积操作尺寸会变为：<strong>5 × 5</strong>（如图），然后再采用上述卷积核进行卷积运算尺寸变为：<strong>3 × 3</strong>，最后再执行一次卷积运算后，尺寸变为了：<strong>1</strong>。</p>
<p>故，从图中可以知道每一个特征图（feature map）上的任一特征（feature map 上任一像素点）的感受野，注意同一特征图上的特征的感受野相同：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Layer1 层特征像素感受野为：3 × 3；</span><br><span class="line">Layer2 层特征像素感受野为：5 × 5；</span><br><span class="line">Layer3 层特征像素感受野为：7 × 7；</span><br></pre></td></tr></table></figure>
<hr>
<p>理解一维上的变化，再来看一个二维特征图的可视化观察感受野的样例：</p>
<p>假设，原始图像的大小为 <strong>10 x 10</strong>，一共设计了 <strong>5</strong> 个网络层，前面 <strong>4</strong> 个是卷积层，卷积核的大小为 <strong>3 x 3</strong>，最后一个是池化层，过滤器大小为 <strong>2 x 2</strong>。步幅 stride 均为：<strong>1</strong>：</p>
<p>注意，这里感受野的计算我们都没有考虑“边界填充”。实际建模过程中一般会填充边界，但原理一样。</p>
<p><strong>–&gt; Get Start</strong></p>
<p>1）Conv_1</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./Conv_1.png" alt="avatar"></p>
<p>–&gt; 从图中可以看出</p>
<p>第一层网络输出（output1）的 feature map：尺寸为 <strong>8 x 8</strong>，特征图中每一个特征（即每一个像素）受到原始图像的 <strong>3 x 3</strong> 区域内像素的影响。故，第一层输出 feature map 的感受野为 <strong>3</strong>，符号记为：</p>
<p><strong>RF1=3 </strong>（特征图上任一像素值与原始图像的 3 x 3 区域有关）</p>
<p>2）Conv_2</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./Conv_2.png" alt="avatar"></p>
<p>–&gt; 从图中可以看出</p>
<p>经历两次卷积运算之后，最终输出（output2）的图像 feature map：尺寸为 <strong>6 x 6</strong>，特征图中每一个特征（即每一个像素点）受到 output1特征图中 <strong>3 x 3</strong> 区域内内像素的影响，而 output1 特征图中的这个 <strong>3 x 3</strong> 区域又受到原始图像的 <strong>5 x 5</strong> 区域内像素的影响。故，第二层输出 feature map 的感受野为 <strong>5</strong>，符号记为：</p>
<p><strong>RF2=5</strong>（特征图上任一像素值与原始图像的 5 x 5 区域有关）</p>
<p>3）Conv_3</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./Conv_3.png" alt="avatar"></p>
<p>–&gt; 从图中可以看出</p>
<p>经历三次卷积运算之后，最终输出（output3）的图像 feature map：尺寸为 <strong>4 x 4</strong>，特征图中每一个特征（即每一个像素点）受到 output2 特征图中 <strong>3 x 3</strong> 区域内内像素的影响，而 output2 特征图中的这个 <strong>3 x 3</strong> 区域又受到 output1 中的 <strong>5 x 5</strong> 区域内像素的影响，然而 output1 特征图中的这个 <strong>5 x 5</strong> 区域又受到原始图像的 <strong>7 x 7</strong> 区域内像素的影响。故，第三层输出 feature map 的感受野为 <strong>7</strong>，符号记为：</p>
<p><strong>RF3=7</strong>（特征图上任一像素值与原始图像的 7 x 7 区域有关）</p>
<p>4）Conv_4</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./Conv_4.png" alt="avatar"></p>
<p>经历四次卷积运算之后，最终输出（output4）的图像 feature map：尺寸为 <strong>2 x 2</strong>，特征图中每一个特征（即每一个像素点）受到 output3 特征图中 <strong>3 x 3</strong> 区域内内像素的影响，而 output3 特征图中的这个 <strong>3 x 3</strong> 区域又受到 output2 中的 <strong>5 x 5</strong> 区域内像素的影响，而 output2 特征图中的这个 <strong>5 x 5</strong> 区域又受到 output1 的 <strong>7 x 7</strong> 区域内像素的影响，然而 output1 特征图中的这个 <strong>7 x 7</strong> 区域又受到原始图像的 <strong>9 x 9</strong> 区域内像素的影响。故，第四层输出 feature map 的感受野为 <strong>9</strong>，符号记为：</p>
<p><strong>RF4=9</strong>（特征图上任一像素值与原始图像的 9 x 9 区域有关）</p>
<p>5）Polling_5</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./Conv_5.png" alt="avatar"></p>
<p>经历四次卷积运算和一次池化运算之后，最终输出（output5）的图像 feature map：尺寸为 <strong>1 x 1</strong>，特征图中每一个特征（即每一个像素点）受到 output4 特征图中 <strong>2 x 2</strong> 区域内内像素的影响，而 output4 特征图中的这个 <strong>2 x 2</strong> 区域又受到 output3 中的 <strong>4 x 4</strong> 区域内像素的影响，而 output3 特征图中的这个 <strong>4 x 4</strong> 区域又受到 output2 的 <strong>6 x 6</strong> 区域内像素的影响，然而 output2 特征图中的这个 <strong>6 x 6</strong> 区域又受到 output1 的 <strong>8 x 8</strong> 区域内像素的影响，然而 output1 特征图中的这个 <strong>8 x 8</strong> 区域又受到原始图像的 <strong>10 x 10</strong> 区域内像素的影响。故，第五层输出 feature map 的感受野为 <strong>10</strong>，符号记为：</p>
<p><strong>RF5=10</strong>（特征图上任一像素值与原始图像的 10 x 10 区域有关）</p>
<hr>
<h4 id="1-2-感受野的计算-（Receptive-Field-Arithmetic）"><a href="#1-2-感受野的计算-（Receptive-Field-Arithmetic）" class="headerlink" title="1.2 感受野的计算 （Receptive Field Arithmetic）"></a>1.2 感受野的计算 （Receptive Field Arithmetic）</h4><p>你可能会想：在计算深度卷积神经网络我不可能一层一层的做卷积操作去获取感受野的大小，有没有直接感受野大小计算公式？</p>
<h5 id="1-2-1-感受野大小计算"><a href="#1-2-1-感受野大小计算" class="headerlink" title="1.2.1 感受野大小计算"></a>1.2.1 感受野大小计算</h5><p>先给出一个感受野大小的计算公式：</p>
<p><strong>$$RF_{l+1} = RF_l + (kernel_size_{l+1} - 1) × feature_stride_l$$</strong></p>
<p>其中，$RF​$ 表示某一特征图层特征的感受野，$l​$ 表示层数，$feature_stride_l​$ 表示第 $l​$ 层网络的特征图层上使用的步长。注意，$l = 0​$ 时表示输入层，$RF_0 = 1​$，$feature_stride_0 = 1​$。</p>
<p>来看一下和第一部分给出的二维特征图的可视化观察感受野大小的结果是否吻合：</p>
<p>1）Conv_1</p>
<p>第一层感受野为：<strong>3</strong></p>
<p><strong>$RF_1 = RF_0 + (kernel_size_1 - 1) × feature_stride_0 = 1 + (3 - 1) × 1 = 3$</strong></p>
<p>2）Conv_2</p>
<p>第二层感受野为：<strong>5</strong></p>
<p><strong>$RF_2 = RF_1 + (kernel_size_2 - 1) × feature_stride_1 = 3 + (3 - 1) × 1 = 5​$</strong></p>
<p>3）Conv_3</p>
<p>第三层感受野为：<strong>7</strong></p>
<p><strong>$RF_3 = RF_2 + (kernel_size_3 - 1) × feature_stride_2 = 5 + (3 - 1) × 1 = 7$</strong></p>
<p>4）Conv_4</p>
<p>第四层感受野为：<strong>9</strong></p>
<p><strong>$RF_4 = RF_3 + (kernel_size_4 - 1) × feature_stride_3 = 7 + (3 - 1) × 1 = 9$</strong></p>
<p>5）Polling_5</p>
<p>第五层感受野为：<strong>10</strong></p>
<p><strong>$RF_4 = RF_3 + (kernel_size_4 - 1) × feature_stride_3 = 9 + (2 - 1) × 1 = 10$</strong></p>
<hr>
<p><strong>–&gt; 两个感受野的例子</strong></p>
<p>1）两层 <strong>3 × 3</strong> 的卷积核卷积操作之后的感受野是 <strong>5 × 5</strong>，其中卷积核（filter）的步长（stride）为1、padding 为0，如下图所示：</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./Conv_RF.png" alt="avatar"></p>
<p>可以看出，两层 <strong>3 × 3</strong> 的卷积核卷积操作之后的感受野和通过一层 <strong>5 × 5</strong> 卷积核卷积操作之后的感受野相同。有相关研究指出两层 <strong>3 × 3</strong> 的卷积核卷积操作可以用来代替一层 <strong>5 × 5</strong> 卷积核卷积操作。</p>
<p>2）三层 <strong>3 × 3</strong> 卷积核操作之后的感受野是 <strong>7 × 7</strong>，其中卷积核的步长为1，padding 为 0，如下图所示：</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./Conv_RF_2.png" alt="avatar"></p>
<p>同理，可以看出三层 <strong>3 × 3</strong> 的卷积核卷积操作之后的感受野和通过一层 <strong>7 × 7</strong> 卷积核卷积操作之后的感受野相同。故三层 <strong>3 × 3</strong> 的卷积核卷积操作可以用来代替一层 <strong>7 × 7</strong> 卷积核卷积操作。</p>
<hr>
<h5 id="1-2-2-有效感受野"><a href="#1-2-2-有效感受野" class="headerlink" title="1.2.2 有效感受野"></a>1.2.2 有效感受野</h5><p>前面我们说的是理论感受野，而特征的有效感受野（实际起作用的感受野）实际上是远小于理论感受野的。</p>
<p>以一个两层 <strong>kernel_size</strong> 为 <strong>3</strong>，步长（stride）为：<strong>1 </strong>的网络为例，我们知道该网络的理论感受野为：<strong>5</strong>。计算流程可以参加下图，其中 $x$ 为输入，$w$ 为卷积权重，$o$ 为卷积后的输出特征。</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./RF_effective.png" alt="avatar"></p>
<p>可以发现，$x_{1,1}​$ 只影响第一层 feature map 中的 $o_{1,1}^1​$，而 $x_{3,3}​$ 会影响第一层 feature map 中的所有特征，即：$o_{1,1}^1，o_{1,2}^1，o_{1,3}^1，o_{2,1}^1，o_{2,2}^1，o_{2,3}^1，o_{3,1}^1，o_{3,2}^1，o_{3,3}^1​$。</p>
<p>第一层的输出全部会影响第二层的 $o_{1,1}^2​$。</p>
<p>于是 $x_{1,1}$ 只能通过 $o_{1,1}^1$ 来影响 $o_{1,1}^2$，而 $x_{3,3}$ 能通过第一层的全部输出特征全部 $o_{1,1}^2$，但二者对对最后的特征  $o_{1,1}^2​$ 的影响却大不相同。可以知道，输入中越靠感受野中间的元素对特征的贡献越大。</p>
<p>这就好比人的眼睛所在的有限视野范围内，总有要  focus 的焦点。换句话说，一个特征点在输入图像（Input） 上所关注的特定区域（也就是其对应的感受野）会在该区域的中心处聚焦，并以指数变化向周边扩展（<em>need more explanation</em>）。</p>
<p>–&gt; 所以，</p>
<p>一个特征点感受野的信息，可以用感受野的中心位置（<strong>center location</strong>）以及感受野大小（size）表示，这是合理的。</p>
<hr>
<h3 id="2-感受野信息"><a href="#2-感受野信息" class="headerlink" title="2 感受野信息"></a>2 感受野信息</h3><p>前面我们给出了，在不考虑填充（Padding）情况下，如何计算 feature map 上特征（像素点）的感受野大小，以及可视化的观察了 feature map 上特征的感受野。</p>
<p>–&gt; 思考一下：</p>
<p>那么，在使用填充的情况下，feature map 上特征（像素点）的感受野大小有哪些变化？特征（像素点）到底受到原始图像像素矩阵的哪一部分影响（位置）？</p>
<p>事实上，关于感受野的解读有个非常经典的博文：<a href="https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807" target="_blank" rel="noopener"><strong>A guide to receptive field arithmetic for Convolutional Neural Networks</strong></a> ，论文中提出一种：“<strong>The fixed-sized CNN feature map visualization</strong>”（固定特征图）的方法实现了更为一般的（使用填充）CNN 感受野计算以及可视化。</p>
<p>先给出 Paper 中的一张经典的卷积神经网络 feature map 可视化以及感受野的示意图：</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./classics.png" alt="avatar"></p>
<p><strong>1 –&gt; Way-1</strong></p>
<p>Way1 对应为通常的一种理解感受野的方式，熟悉么？它就是我们在上文给出的二维特征图的可视化观察感受野的样例（差别在于上文没有使用填充）。</p>
<p>图解如下：</p>
<p>Way1（左侧）中上方的图，是在 <strong>5 x 5</strong> 的图像（蓝色区域）上做一个 <strong>3 x 3</strong> 卷积核的卷积计算操作，步长为 <strong>2</strong>，padding 为 <strong>1</strong>，所以输出为 <strong>3 x 3</strong> 的特征图（绿色区域）。那么该特征图上的每个特征（1 × 1）对应的感受野，就是 <strong>3 x 3</strong>。</p>
<p>Way1（左侧）中下方的图，是在上面的基础上再加了一个完全一样的卷积层。对于经过第二层卷积后其上的一个特征（如，红色圈对应的特征像素点）在上一层特征图上“感受”到 <strong>3 x 3</strong> 大小，该 <strong>3 x 3</strong> 大小的每个特征再映射回到图像上，就会发现由 <strong>7 x 7</strong> 个像素点与之关联（需要考虑填充）。</p>
<p>于是，我们就可以说第二层卷积后的特征其感受野大小是 <strong>7 x 7</strong> 的。</p>
<p>这对我们来说是熟悉的。</p>
<p><strong>2 –&gt; Way-2</strong></p>
<p>这里我们主要来看第二种方式，就是：使用 <strong>The fixed-sized CNN feature map visualization </strong> 固定特征图的方式来跟踪感受野信息（center location &amp;&amp; size）。</p>
<p>固定特征图意思就是，将每一卷积层输出的特征图层和输入图像保持一致，事实上，和 Way1 主要的区别仅仅是将两层特征图上的特征不进行“合成”，而是保留其在前一层因“步长”而产生的影响。</p>
<p>Way2 的理解方式其实更具有一般性，我们可以无需考虑输入图像的大小对感受野进行计算。如下图：</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./classics_2.png" alt="avatar"></p>
<p>图上虽绘制了输入为 <strong>9 x 9</strong> 的图像（蓝色区域），但是它的大小情况是无关紧要的。因为我们现在只关注以某“无限”大小图像某一像素点为中心的一块区域进行卷积操作。</p>
<p>首先，经过一个 <strong>3 x 3</strong> 的卷积层（padding=1，stride=2）后，可以得到特征输出（深绿色）部分。其中深绿色的特征分别表示卷积核扫过输入图像时，卷积核中心点所在的相对位置。此时，每个深绿色特征的感受野是 <strong>3 x 3</strong> （浅绿），它和卷积核大小是相同的。这很好理解，每一个绿色特征值的贡献来源是原始图像中心点像素周围一个 <strong>3 x 3</strong> 面积。</p>
<p>再叠加一个 <strong>3 x 3</strong> 的卷积层（padding=1，stride=2）后，输出得到 <strong>3 x 3</strong> 的特征输出（橙色）。此时的中心点的感受野所对应的是黄色区域 <strong>7 x 7</strong>，代表的是输入图像在中心点橙色特征所做的贡献。</p>
<p>此时，由于每一卷积层输出的特征图层和输入图像保持一致，无需映射，我们可以直接观察到最终 feature map 中特征在原始图像中的映射区域（哎？!好像感受野位置和尺寸都有了）。</p>
<hr>
<h4 id="感受野计算"><a href="#感受野计算" class="headerlink" title="感受野计算"></a>感受野计算</h4><p>直观的感受了感受野之后，究竟该如何计算更为一般的感受野大小以及感受野中心位置（特征位置）。</p>
<p>从 Way2 中我们已经发觉到，某一层特征上的感受野大小依赖的要素有：每一层的卷积核大小 <strong>k</strong>，padding 大小 <strong>p</strong>，步长（stride） <strong>s</strong>。</p>
<p>在推导某层的感受野时，还需要考虑到该层之前各层上特征的的感受野大小 <strong>r</strong>，以及各 feature map 中相邻特征之间的距离 <strong>j</strong>（jump）。</p>
<p>所以对于某一卷积层（卷积核大小 k，padding 大小 p，stride s）上某特征的感受野大小公式为：</p>
<p><strong>$$j_{out} = j_{in}  × s ​$$</strong></p>
<p><strong>$$r_{out} = r_{in} + (k_{out} - 1) × j_{in} ​$$</strong></p>
<p><strong>$$start_{out} = start_{in} + ((k_{out} -1)/2 - p) × j_{in}$$</strong></p>
<p>–&gt; 第一式：</p>
<p>第一行计算的是，相邻特征之间的距离（jump）。各层里的特征之间的距离显然是严重依赖于 stride 的，并且逐层累积。</p>
<p>注意，<strong>$j_{0}​$</strong>：输入图像的作为起始像素特征，它的特征距离（jump） 为：<strong>1</strong>。</p>
<p>–&gt; 第二式：</p>
<p>第二行计算的就是某层的特征的感受大小。它依赖于上一层的特征的感受野大小 <strong>$r_{in}$</strong> 和特征之间的距离 <strong>$j_{in}$</strong>，以及该层的卷积核大小 k。</p>
<p>注意，<strong>$r_{1}​$</strong>：输入图像的每个像素作为特征的感受野就是其自身，为 <strong>1</strong>。</p>
<p>–&gt; 第三式：</p>
<p>第三行公式计算的是特征感受野的几何半径。对于处于特征图边缘处的特征来说，这类特征的感受野并不会完整的对应到原输入图像上的区域，都会小一些。</p>
<p>注意，<strong>$start_{0}​$</strong>：初始特征的感受野几何半径为 <strong>0.5</strong>。</p>
<p>下面，我们继续拿可视化时用的例子，看看具体是怎么计算和对应的：</p>
<p><img src="/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/./classics_3.png" alt="avatar"></p>
<p>上图中除了公式和说明部分外，有两行分别代表的是第一层卷积和第二层卷积。在每行中，应从左往右观察卷积核计算和操作。</p>
<p>第一层比较简单，最后输出 <strong>3 x 3</strong> 绿色的特征图，每个特征有阴影框大小来表示每个特征对应的感受野大小 <strong>3 x 3</strong>。其中  表示的 <strong>0.5</strong> 几何半径，我已经用红色标识出来，对应于阴影面积覆盖到的绿色面积的几何半径。</p>
<p>第二层，由于有一个单位的 padding，所以 3x3 卷积核是按照蓝色箭头标记作为的起始方向开始，在所有的绿色位置上挪动的。最后算得特征的感受野大小为 7x7，亦对应于阴影框和阴影区域部分。其中 $start_{2}$ 是 0.5 也已经用红色标记了出来。</p>
<p>–&gt; 结论：</p>
<p>CNN的第一层是输入层，<strong>n = image size，r = 1，j = 1，start = 0.5</strong>。</p>
<p>上图中，采用的坐标系中输入层的第一个特征中心位置在 <strong>0.5</strong>。递归执行上述四个公式，就可以计算 CNN 中所有特征图中的感受野信息。</p>
<p>也就是说，只要知道了各 feature map 中相邻特征之间的间隔（jump），就可以获得特征在原始图像中的相对坐标了。</p>
<hr>
<h3 id="3-Python-Script"><a href="#3-Python-Script" class="headerlink" title="3. Python Script"></a>3. Python Script</h3><p>这一部分给出一个用于计算给定卷积神经网络架构（AlexNet、VGG16）下所有层的感受野信息的 Pyhthon 实现。</p>
<p>程序允许输入任何特征图的名称和图中特征的索引号，输出相关感受野的尺寸和位置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># [filter size, stride, padding] </span></span><br><span class="line"><span class="comment">#Assume the two dimensions are the same </span></span><br><span class="line"><span class="comment">#Each kernel requires the following parameters: </span></span><br><span class="line"><span class="comment"># - k_i: kernel size </span></span><br><span class="line"><span class="comment"># - s_i: stride </span></span><br><span class="line"><span class="comment"># - p_i: padding (if padding is uneven, right padding will higher than left padding; "SAME" option in tensorflow) </span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#Each layer i requires the following parameters to be fully represented: </span></span><br><span class="line"><span class="comment"># - n_i: number of feature (data layer has n_1 = imagesize ) </span></span><br><span class="line"><span class="comment"># - j_i: distance (projected to image pixel distance) between center of two adjacent features </span></span><br><span class="line"><span class="comment"># - r_i: receptive field of a feature in layer i </span></span><br><span class="line"><span class="comment"># - start_i: position of the first feature's receptive field in layer i (idx start from 0, negative means the center fall into padding)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math </span><br><span class="line"></span><br><span class="line">supportedList = &#123;<span class="string">'AlexNet'</span>: &#123;<span class="string">'convnet'</span>: [[<span class="number">11</span>,<span class="number">4</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">6</span>,<span class="number">1</span>,<span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>]], </span><br><span class="line">                             <span class="string">'layer_names'</span>: [<span class="string">'conv1'</span>,<span class="string">'pool1'</span>,<span class="string">'conv2'</span>,<span class="string">'pool2'</span>,<span class="string">'conv3'</span>,<span class="string">'conv4'</span>,<span class="string">'conv5'</span>,<span class="string">'pool5'</span>,<span class="string">'fc6-conv'</span>, <span class="string">'fc7-conv'</span>]&#125;,</span><br><span class="line"></span><br><span class="line">                <span class="string">'VGG16'</span>: &#123;<span class="string">'convnet'</span>: [[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">                                      [<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>]], </span><br><span class="line">                          <span class="string">'layer_names'</span>: [<span class="string">'conv1_1'</span>,<span class="string">'conv1_2'</span>,<span class="string">'pool1'</span>,<span class="string">'conv2_1'</span>,<span class="string">'conv2_2'</span>,<span class="string">'pool2'</span>,<span class="string">'conv3_1'</span>,<span class="string">'conv3_2'</span>,</span><br><span class="line">                                          <span class="string">'conv3_3'</span>, <span class="string">'pool3'</span>,<span class="string">'conv4_1'</span>,<span class="string">'conv4_2'</span>,<span class="string">'conv4_3'</span>,<span class="string">'pool4'</span>,<span class="string">'conv5_1'</span>,<span class="string">'conv5_2'</span>,<span class="string">'conv5_3'</span>,<span class="string">'pool5'</span>]&#125;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">imsize = <span class="number">227</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">outFromIn</span><span class="params">(conv, layerIn)</span>:</span> </span><br><span class="line">    n_in = layerIn[<span class="number">0</span>] </span><br><span class="line">    j_in = layerIn[<span class="number">1</span>] </span><br><span class="line">    r_in = layerIn[<span class="number">2</span>] </span><br><span class="line">    start_in = layerIn[<span class="number">3</span>]</span><br><span class="line">    k = conv[<span class="number">0</span>] </span><br><span class="line">    s = conv[<span class="number">1</span>] </span><br><span class="line">    p = conv[<span class="number">2</span>] </span><br><span class="line"></span><br><span class="line">    n_out = math.floor((n_in - k + <span class="number">2</span>*p)/s) + <span class="number">1</span> </span><br><span class="line">    actualP = (n_out<span class="number">-1</span>)*s - n_in + k </span><br><span class="line">    pR = math.ceil(actualP/<span class="number">2</span>) </span><br><span class="line">    pL = math.floor(actualP/<span class="number">2</span>) </span><br><span class="line"></span><br><span class="line">    j_out = j_in * s </span><br><span class="line">    r_out = r_in + (k - <span class="number">1</span>)*j_in </span><br><span class="line">    start_out = start_in + ((k<span class="number">-1</span>)/<span class="number">2</span> - pL)*j_in </span><br><span class="line">    <span class="keyword">return</span> n_out, j_out, r_out, start_out</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printLayer</span><span class="params">(layer, layer_name)</span>:</span> </span><br><span class="line">    print(layer_name + <span class="string">":"</span>) </span><br><span class="line">    print(<span class="string">"\t n features: %s \n \t jump: %s \n \t receptive size: %s \t start: %s "</span> % (layer[<span class="number">0</span>], layer[<span class="number">1</span>], layer[<span class="number">2</span>], layer[<span class="number">3</span>])) </span><br><span class="line"></span><br><span class="line">layerInfos = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># first layer is the data layer (image) with n_0 = image size; j_0 = 1; r_0 = 1; and start_0 = 0.5</span></span><br><span class="line">    net_name = input(<span class="string">"Supported List [AlexNet, VGG16]\n"</span></span><br><span class="line">        <span class="string">"Please enter the selected target convolution network name &gt; "</span>)</span><br><span class="line">    convnet = supportedList[net_name][<span class="string">'convnet'</span>]</span><br><span class="line">    layer_names = supportedList[net_name][<span class="string">'layer_names'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"|-------------- Net summary --------------|"</span>)</span><br><span class="line">    currentLayer = [imsize, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0.5</span>]</span><br><span class="line">    printLayer(currentLayer, <span class="string">"input image"</span>) </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(convnet)): </span><br><span class="line">        currentLayer = outFromIn(convnet[i], currentLayer)  </span><br><span class="line">        layerInfos.append(currentLayer) </span><br><span class="line">        printLayer(currentLayer, layer_names[i])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"------------------------------------------"</span>) </span><br><span class="line">    layer_name = input(<span class="string">"Layer name where the feature in: "</span>)    </span><br><span class="line">    layer_idx = layer_names.index(layer_name) </span><br><span class="line">    idx_x = int(input(<span class="string">"index of the feature in x dimension (from 0)"</span>)) </span><br><span class="line">    idx_y = int(input (<span class="string">"index of the feature in y dimension (from 0)"</span>)) </span><br><span class="line"></span><br><span class="line">    n = layerInfos[layer_idx][<span class="number">0</span>] </span><br><span class="line">    j = layerInfos[layer_idx][<span class="number">1</span>] </span><br><span class="line">    r = layerInfos[layer_idx][<span class="number">2</span>] </span><br><span class="line">    start = layerInfos[layer_idx][<span class="number">3</span>] </span><br><span class="line">    <span class="keyword">assert</span>(idx_x &lt; n) </span><br><span class="line">    <span class="keyword">assert</span>(idx_y &lt; n)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"receptive field: (%s, %s)"</span> % (r, r)) </span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"center: (%s, %s)"</span> % (start+idx_x*j, start+idx_y*j))</span><br></pre></td></tr></table></figure>
<p>在 AlexNet 网络上的效果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">-------Net summary------</span><br><span class="line">input image:</span><br><span class="line">         n features: <span class="number">227</span></span><br><span class="line">         jump: <span class="number">1</span></span><br><span class="line">         receptive size: <span class="number">1</span>       start: <span class="number">0.5</span></span><br><span class="line">conv1:</span><br><span class="line">         n features: <span class="number">55</span></span><br><span class="line">         jump: <span class="number">4</span></span><br><span class="line">         receptive size: <span class="number">11</span>      start: <span class="number">5.5</span></span><br><span class="line">pool1:</span><br><span class="line">         n features: <span class="number">27</span></span><br><span class="line">         jump: <span class="number">8</span></span><br><span class="line">         receptive size: <span class="number">19</span>      start: <span class="number">9.5</span></span><br><span class="line">conv2:</span><br><span class="line">         n features: <span class="number">27</span></span><br><span class="line">         jump: <span class="number">8</span></span><br><span class="line">         receptive size: <span class="number">51</span>      start: <span class="number">9.5</span></span><br><span class="line">pool2:</span><br><span class="line">         n features: <span class="number">13</span></span><br><span class="line">         jump: <span class="number">16</span></span><br><span class="line">         receptive size: <span class="number">67</span>      start: <span class="number">17.5</span></span><br><span class="line">conv3:</span><br><span class="line">         n features: <span class="number">13</span></span><br><span class="line">         jump: <span class="number">16</span></span><br><span class="line">         receptive size: <span class="number">99</span>      start: <span class="number">17.5</span></span><br><span class="line">conv4:</span><br><span class="line">         n features: <span class="number">13</span></span><br><span class="line">         jump: <span class="number">16</span></span><br><span class="line">         receptive size: <span class="number">131</span>     start: <span class="number">17.5</span></span><br><span class="line">conv5:</span><br><span class="line">         n features: <span class="number">13</span></span><br><span class="line">         jump: <span class="number">16</span></span><br><span class="line">         receptive size: <span class="number">163</span>     start: <span class="number">17.5</span></span><br><span class="line">pool5:</span><br><span class="line">         n features: <span class="number">6</span></span><br><span class="line">         jump: <span class="number">32</span></span><br><span class="line">         receptive size: <span class="number">195</span>     start: <span class="number">33.5</span></span><br><span class="line">fc6-conv:</span><br><span class="line">         n features: <span class="number">1</span></span><br><span class="line">         jump: <span class="number">32</span></span><br><span class="line">         receptive size: <span class="number">355</span>     start: <span class="number">113.5</span></span><br><span class="line">fc7-conv:</span><br><span class="line">         n features: <span class="number">1</span></span><br><span class="line">         jump: <span class="number">32</span></span><br><span class="line">         receptive size: <span class="number">355</span>     start: <span class="number">113.5</span></span><br><span class="line">------------------------</span><br><span class="line">Layer name where the feature <span class="keyword">in</span>: pool5</span><br><span class="line">index of the feature <span class="keyword">in</span> x dimension (<span class="keyword">from</span> <span class="number">0</span>)<span class="number">3</span></span><br><span class="line">index of the feature <span class="keyword">in</span> y dimension (<span class="keyword">from</span> <span class="number">0</span>)<span class="number">3</span></span><br><span class="line">receptive field: (<span class="number">195</span>, <span class="number">195</span>)</span><br><span class="line">center: (<span class="number">129.5</span>, <span class="number">129.5</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="4-感受野的应用"><a href="#4-感受野的应用" class="headerlink" title="4.感受野的应用"></a>4.感受野的应用</h3><p><strong>1 –&gt; Recoginition</strong></p>
<p>Xudong Cao写过一篇叫《A practical theory for designing very deep convolutional neural networks》的technical report，里面讲设计基于深度卷积神经网络的图像分类器时，为了保证得到不错的效果，需要满足两个条件：</p>
<blockquote>
<p>Firstly, for each convolutional layer, its capacity of learning more complex patterns should be guaranteed; Secondly, <strong>the receptive field of the top most layer should be no larger than the image region</strong>.</p>
</blockquote>
<p>其中，第二个条件就是对卷积神经网络最高层网络特征感受野大小的限制。</p>
<p><strong>2 –&gt; Object Detection</strong></p>
<p>现在流行的目标检测网络大部分都是基于 anchor 的，比如 SSD 系列，v2 以后的 yolo，还有 faster rcnn 系列。</p>
<p>基于anchor 的目标检测网络会预设一组大小不同的 anchor，比如 32x32、64x64、128x128、256x256，这么多anchor，我们应该放置在哪几层比较合适呢？这个时候感受野的大小是一个重要的考虑因素。</p>
<p>放置 anchor 层的特征感受野应该跟 anchor 大小相匹配，感受野比 anchor 大太多不好，小太多也不好。如果感受野比 anchor 小很多，就好比只给你一只脚，让你说出这是什么鸟一样。如果感受野比 anchor 大很多，则好比给你一张世界地图，让你指出故宫在哪儿一样。</p>
<p>《S3FD: Single Shot Scale-invariant Face Detector》这篇人脸检测器论文就是依据感受野来设计anchor的大小的一个例子，文中的原话是：</p>
<blockquote>
<p>we design anchor scales based on <strong>the effective receptive field</strong></p>
</blockquote>
<p>《FaceBoxes: A CPU Real-time Face Detector with High Accuracy》这篇论文在设计多尺度anchor的时候，依据同样是感受野，文章的一个贡献为:</p>
<blockquote>
<p>We introduce the Multiple Scale Convolutional Layers<br>(MSCL) to handle various scales of face via <strong>enriching</strong><br><strong>receptive fields and discretizing anchors over layers</strong></p>
</blockquote>
<hr>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://iphysresearch.github.io/posts/receptive_field.html" target="_blank" rel="noopener">https://iphysresearch.github.io/posts/receptive_field.html</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/40267131" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40267131</a></p>
<p><a href="https://iphysresearch.github.io/posts/receptive_field.html" target="_blank" rel="noopener">https://iphysresearch.github.io/posts/receptive_field.html</a></p>

      
    </div>
    
    
    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">如果感觉文章对您有较大帮助，请随意打赏。您的鼓励是我保持持续创作的最大动力！</div>
    
</div>
      
    </div>

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div></div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/uploads/wechatpay.png" alt="TheMusicIsLoud 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/uploads/alipay.png" alt="TheMusicIsLoud 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    TheMusicIsLoud
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/" title="一文读懂卷积神经网络感受野(Receptive Field)">http://yoursite.com/Convlutional-Neural-Networks/一文读懂卷积神经网络感受野-Receptive-Field/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/TensorFlow/" rel="tag"><i class="fa fa-tag"></i> TensorFlow</a>
          
            <a href="/tags/ConvolutionNN/" rel="tag"><i class="fa fa-tag"></i> ConvolutionNN</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/Convlutional-Neural-Networks/卷积神经网络系列之-CNN-进化史/" rel="next" title="卷积神经网络系列之 CNN 进化史">
                <i class="fa fa-chevron-left"></i> 卷积神经网络系列之 CNN 进化史
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/Convlutional-Neural-Networks/卷积神经网络系列之从-LeNet-到-AlexNet/" rel="prev" title="卷积神经网络系列之从 LeNet 到 AlexNet">
                卷积神经网络系列之从 LeNet 到 AlexNet <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
<span class="jiathis_txt">分享到：</span>
<a class="jiathis_button_fav">收藏夹</a>
<a class="jiathis_button_copy">复制网址</a>
<a class="jiathis_button_email">邮件</a>
<a class="jiathis_button_weixin">微信</a>
<a class="jiathis_button_qzone">QQ空间</a>
<a class="jiathis_button_tqq">腾讯微博</a>
<a class="jiathis_button_douban">豆瓣</a>
<a class="jiathis_button_share">一键分享</a>

<a href="http://www.jiathis.com/share?uid=2140465" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a>
<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript">
var jiathis_config={
  data_track_clickback:true,
  summary:"",
  shortUrl:false,
  hideMore:false
}
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=" charset="utf-8"></script>
<!-- JiaThis Button END -->
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80MjA5OC8xODY0NQ=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/uploads/header.jpg" alt="TheMusicIsLoud">
            
              <p class="site-author-name" itemprop="name">TheMusicIsLoud</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">81</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">91</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/TheNightIsYoung" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://dev.tencent.com/" title="CloudStudio&&Coding" target="_blank">CloudStudio&&Coding</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-到底什么是感受野（Receptive-Field）？"><span class="nav-text">1. 到底什么是感受野（Receptive Field）？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-CNN-Feature-Map-Visualization"><span class="nav-text">1.1 CNN Feature Map  Visualization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-感受野的计算-（Receptive-Field-Arithmetic）"><span class="nav-text">1.2 感受野的计算 （Receptive Field Arithmetic）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-2-1-感受野大小计算"><span class="nav-text">1.2.1 感受野大小计算</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#1-2-2-有效感受野"><span class="nav-text">1.2.2 有效感受野</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-感受野信息"><span class="nav-text">2 感受野信息</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#感受野计算"><span class="nav-text">感受野计算</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Python-Script"><span class="nav-text">3. Python Script</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-感受野的应用"><span class="nav-text">4.感受野的应用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reference"><span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">TheMusicIsLoud</span>

  
</div>

<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>

-->


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info//busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      本站访客数<span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      本站总访问量<span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("L40cS1OTf2nXQmbIANou8HvS-gzGzoHsz", "t0xHBc4DURRDc9MDSKX7vx8c");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
