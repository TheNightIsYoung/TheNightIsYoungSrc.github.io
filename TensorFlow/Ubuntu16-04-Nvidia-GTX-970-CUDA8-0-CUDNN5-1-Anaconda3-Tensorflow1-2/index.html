<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">

  <script>
    (function(){
        if(''){
            if (prompt('请输入密码') !== ''){
                alert('密码错误');
                history.back();
            }
        }
    })();
</script>







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="TensorFlow,GPU,CUDA&&CUDNN,">





  <link rel="alternate" href="/atom.xml" title="When Art Meets Technology" type="application/atom+xml">






<meta name="description" content="愿你每天欢喜多于悲，孤独有人陪…   写在前面： 关于搭建 TensorFlow [GPU Support] 环境： 搭建基于 GPU 显卡加速运算的 TensorFlow 深度学习环境前，建议先明确当前服务器独立显卡（GPU ）详细信息（包括显卡型号、显存、计算性能等等）。这是因为，TensorFlow只支持某些类型的显卡（N卡：Nvidia），有些 TensorFlow 模型需要较大的 GP">
<meta name="keywords" content="TensorFlow,GPU,CUDA&amp;&amp;CUDNN">
<meta property="og:type" content="article">
<meta property="og:title" content="Ubuntu16.04 + Nvidia GTX 970 + CUDA8.0 + CUDNN5.1 + Anaconda3 + Tensorflow1.2">
<meta property="og:url" content="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/index.html">
<meta property="og:site_name" content="When Art Meets Technology">
<meta property="og:description" content="愿你每天欢喜多于悲，孤独有人陪…   写在前面： 关于搭建 TensorFlow [GPU Support] 环境： 搭建基于 GPU 显卡加速运算的 TensorFlow 深度学习环境前，建议先明确当前服务器独立显卡（GPU ）详细信息（包括显卡型号、显存、计算性能等等）。这是因为，TensorFlow只支持某些类型的显卡（N卡：Nvidia），有些 TensorFlow 模型需要较大的 GP">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/driver_search.png">
<meta property="og:image" content="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/driver_info.png">
<meta property="og:image" content="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/cuda8_1.png">
<meta property="og:image" content="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/cuda8_2.png">
<meta property="og:image" content="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/nvcc.png">
<meta property="og:image" content="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/deviceQuery.png">
<meta property="og:image" content="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/cudnn.png">
<meta property="og:image" content="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/cuda_download.png">
<meta property="og:image" content="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/cuda9.jpg">
<meta property="og:updated_time" content="2019-05-29T03:03:52.236Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ubuntu16.04 + Nvidia GTX 970 + CUDA8.0 + CUDNN5.1 + Anaconda3 + Tensorflow1.2">
<meta name="twitter:description" content="愿你每天欢喜多于悲，孤独有人陪…   写在前面： 关于搭建 TensorFlow [GPU Support] 环境： 搭建基于 GPU 显卡加速运算的 TensorFlow 深度学习环境前，建议先明确当前服务器独立显卡（GPU ）详细信息（包括显卡型号、显存、计算性能等等）。这是因为，TensorFlow只支持某些类型的显卡（N卡：Nvidia），有些 TensorFlow 模型需要较大的 GP">
<meta name="twitter:image" content="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/driver_search.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/">






  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice")
  daovoice('init', {
      app_id: "7e6ff6a0"
    });
  daovoice('update');
  </script>

  <title>Ubuntu16.04 + Nvidia GTX 970 + CUDA8.0 + CUDNN5.1 + Anaconda3 + Tensorflow1.2 | When Art Meets Technology</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  
    <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">When Art Meets Technology</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TheMusicIsLoud">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="When Art Meets Technology">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Ubuntu16.04 + Nvidia GTX 970 + CUDA8.0 + CUDNN5.1 + Anaconda3 + Tensorflow1.2</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-06T16:56:58+08:00">
                2018-06-06
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-05-29T11:03:52+08:00">
                2019-05-29
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/TensorFlow/" itemprop="url" rel="index">
                    <span itemprop="name">TensorFlow</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/" class="leancloud_visitors" data-flag-title="Ubuntu16.04 + Nvidia GTX 970 + CUDA8.0 + CUDNN5.1 + Anaconda3 + Tensorflow1.2">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读热度&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
                 <span>次</span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  8.9k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  43
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <center> 愿你每天欢喜多于悲，孤独有人陪… </center>

<p><strong>写在前面：</strong></p>
<p>关于搭建 <strong>TensorFlow [GPU Support]</strong> 环境：</p>
<p>搭建基于 GPU 显卡加速运算的 TensorFlow 深度学习环境前，建议先明确当前服务器独立显卡（GPU ）详细信息（包括显卡型号、显存、计算性能等等）。这是因为，TensorFlow只支持某些类型的显卡（N卡：Nvidia），有些 TensorFlow 模型需要较大的 GPU 内存，或更多的 GPU 计算核心（即更强的计算能力，加速模型运算），了解服务器中 GPU 的详细信息可以更好的帮助我们进行计算加速。</p>
<p>然后依据附录中的 <strong>Tensorflow&amp;&amp;NVIDIA 版本信息对照表</strong>，选择安装相互兼容的显卡并行计算包（CUDA）、深度神经网络 GPU 加速包（CUDNN）以及相应版本的 Tensorflow 即可。</p>
<a id="more"></a>
<hr>
<h3 id="Environmental-introduction"><a href="#Environmental-introduction" class="headerlink" title="Environmental introduction"></a>Environmental introduction</h3><p><strong>搭建环境: </strong></p>
<p>Ubuntu16.04 + Nvidia GeForce GTX 970 + CUDA8.0 + CUDNN5.1 + Anaconda3 + Tensorflow1.2</p>
<p><strong>硬件环境介绍:</strong></p>
<ol>
<li><p>搭载 Nvidia GeForce GTX 970 独立显卡联想 ThinkCentre 商业主机；</p>
</li>
<li><p>搭载 3TB 硬盘用于存储数据以及 32GB（4 * 8GB）内存条；</p>
</li>
<li><p>四核心 Inter CORE I7 CPU；</p>
</li>
<li><p>ThinkCentre 服务器安装 Ubuntu16.04。</p>
</li>
</ol>
<p><strong>联想 ThinkCentre 商业主机搭载 Nvidia GTX 960 独立显卡时问题：</strong></p>
<ol>
<li><p>电源提供接口不够，购买电源转接线电源口 IDE 大 4D 芯一分二（4 pin公转母），显卡 6pin 转双大 4D。电源接线不够时，建议升级较大功率电源。</p>
</li>
<li><p>机箱主板空间较小无法安装索泰（ZOTAC）Nvidia GTX 970 独立显卡，购买 PCI-E 16X 显卡延长线。</p>
</li>
<li><p>购买 DVI 转 VGA24+5 Pin（显卡显示器高清视频转换接头）。</p>
</li>
</ol>
<p><strong>CUDA &amp;&amp; CUDNN</strong></p>
<p>再来了解一下什么是 CUDA 和 CUDNN：</p>
<p>CUDA 是显卡厂商 NVIDIA 推出的通用并行计算架构（平台），它使得 GPU 能够解决并行的、复杂的计算问题。</p>
<p>CUDNN 其实就是 cuDNN（CUDA DNN），它是深度神经网络的 GPU 加速库。想要在 CUDA 上运行深度神经网络，就要安装 cuDNN。</p>
<hr>
<h3 id="1-Nvidia-GTX-970-安装显卡驱动"><a href="#1-Nvidia-GTX-970-安装显卡驱动" class="headerlink" title="1. Nvidia GTX 970 安装显卡驱动"></a>1. Nvidia GTX 970 安装显卡驱动</h3><p>搭建 <strong>TensorFlow [GPU Support]</strong> 环境第一步就是要解决显卡驱动问题，具体步骤如下：</p>
<hr>
<h4 id="1-1-查询-GPU-详细信息"><a href="#1-1-查询-GPU-详细信息" class="headerlink" title="1.1 查询 GPU 详细信息"></a>1.1 查询 GPU 详细信息</h4><p>搭载 GPU 独显的服务器安装 Ubuntu16.04 后（接 GPU 显示输出）：</p>
<p>1）查询本机的显卡型号</p>
<p>因显卡一般是 PCI 接口，可以通过 <code>lspci</code> 查询显卡相关信息。一般我们可以查看到两种类型显卡：一块时集显；一块是独显。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lspci -vnn |grep VGA -A 12</span><br><span class="line">01:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM206 [GeForce GTX 960] [10de:1401] (rev a1) (prog-if 00 [VGA controller])</span><br><span class="line">        Subsystem: ZOTAC International (MCO) Ltd. GM206 [GeForce GTX 960] [19da:1379]</span><br><span class="line">        Flags: bus master, fast devsel, latency 0, IRQ 124</span><br><span class="line">        Memory at f6000000 (32-bit, non-prefetchable) [size=16M]</span><br><span class="line">        Memory at e0000000 (64-bit, prefetchable) [size=256M]</span><br><span class="line">        Memory at f0000000 (64-bit, prefetchable) [size=32M]</span><br><span class="line">        I/O ports at e000 [size=128]</span><br><span class="line">        Expansion ROM at 000c0000 [disabled] [size=128K]</span><br><span class="line">        Capabilities: [60] Power Management version 3</span><br><span class="line">        Capabilities: [68] MSI: Enable+ Count=1/1 Maskable- 64bit+</span><br><span class="line">        Capabilities: [78] Express Legacy Endpoint, MSI 00</span><br><span class="line">        Capabilities: [100] Virtual Channel</span><br><span class="line">        Capabilities: [258] L1 PM Substates</span><br></pre></td></tr></table></figure>
<p>===============================================================</p>
<p><strong>显卡信息：</strong></p>
<p>独立显卡: 硬件厂商 NAVIDA（N卡）；型号名称 GM206（GeForce GTX 960）。</p>
<p>集成显卡: 这里由于直接是搭载 GPU 的服务器安装系统，所以集显驱动未安装，无法看到集显信息。</p>
<p>===============================================================</p>
<p>2）确认本机显卡驱动是否正常加载</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lshw -C display</span><br><span class="line">$ sudo lshw -C display</span><br><span class="line">  *-display</span><br><span class="line">       description: VGA compatible controller</span><br><span class="line">       product: GM206 [GeForce GTX 960]</span><br><span class="line">       vendor: NVIDIA Corporation</span><br><span class="line">       physical id: 0</span><br><span class="line">       bus info: pci@0000:01:00.0</span><br><span class="line">       version: a1</span><br><span class="line">       width: 64 bits</span><br><span class="line">       clock: 33MHz</span><br><span class="line">       capabilities: pm msi pciexpress vga_controller bus_master cap_list rom</span><br><span class="line">       configuration: driver=nouveau latency=0</span><br><span class="line">       resources: irq:124 memory:f6000000-f6ffffff memory:e0000000-efffffff memory:f0000000-f1ffffff ioport:e000(size=128) memory:c0000-dffff</span><br></pre></td></tr></table></figure>
<p>输出信息 <code>configuration</code> 字段中，如果 <code>driver=“驱动名称”</code> 不为空，说明系统支持该显卡的驱动；</p>
<p>我们可以看出，Ubuntu 系统支持 GTX 970 显卡且自动安装有一个默认的显卡驱动：<code>nouveau</code>（Linux 开源的显卡驱动），但 <code>nouveau</code>  驱动开发不是很完善。</p>
<p>事实上，我们需要重新安装适合显卡的（这里是 GTX970） Nvidia 显卡驱动才可以正常使用深度学习显卡加速。下面我们来看如何安装合适的 Nvidia 显卡驱动：</p>
<hr>
<h4 id="1-2-查询适合的-Nvidia-驱动"><a href="#1-2-查询适合的-Nvidia-驱动" class="headerlink" title="1.2 查询适合的 Nvidia 驱动"></a>1.2 查询适合的 Nvidia 驱动</h4><p>1）首先打开以及登陆 <a href="http://www.nvidia.com/Download/index.aspx?lang=en-us" target="_blank" rel="noopener">Nvidia Driver 官网</a> 根据独立显卡型号查询适合自己显卡的驱动：</p>
<p><img src="/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/driver_search.png" alt="avatar"></p>
<p>2）显卡驱动信息查询</p>
<p><img src="/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/driver_info.png" alt="avatar"></p>
<hr>
<h4 id="1-3-安装-Nvidia-驱动"><a href="#1-3-安装-Nvidia-驱动" class="headerlink" title="1.3 安装 Nvidia 驱动"></a>1.3 安装 Nvidia 驱动</h4><p>查询到适用的 Nvidia 驱动版本后，开始安装 Nvidia 驱动 390.25：</p>
<p>1）使用 PPA 安装</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo add-apt-repository ppa:graphics-drivers/ppa</span><br></pre></td></tr></table></figure>
<p>第一次运行会出现如下的警告：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Fresh drivers from upstream, currently shipping Nvidia.</span><br><span class="line"></span><br><span class="line"><span class="comment">## Current Status</span></span><br><span class="line">We currently recommend: `nvidia-361`, Nvidia<span class="string">'s current long lived branch.</span></span><br><span class="line"><span class="string">For GeForce 8 and 9 series GPUs use `nvidia-340`</span></span><br><span class="line"><span class="string">For GeForce 6 and 7 series GPUs use `nvidia-304`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## What we'</span>re working on right now:</span><br><span class="line">- Normal driver updates</span><br><span class="line">- Investigating how to bring this goodness to distro on a cadence.</span><br><span class="line">- </span><br><span class="line"><span class="comment">## WARNINGS:</span></span><br><span class="line">This PPA is currently <span class="keyword">in</span> testing, you should be experienced with packaging before you dive <span class="keyword">in</span> here. Give us a few days to sort out the kinks.</span><br><span class="line">Volunteers welcome! See also: https://github.com/mamarley/nvidia-graphics-drivers/</span><br><span class="line"></span><br><span class="line">http://www.ubuntu.com/download/desktop/contribute</span><br><span class="line">更多信息： https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa</span><br><span class="line">按回车继续或者 Ctrl+c 取消添加</span><br></pre></td></tr></table></figure>
<p>–&gt; Enter 后继续：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Enter 后显示如下信息表示添加成功：</span></span><br><span class="line">gpg: keyring `/tmp/tmp7b1tsfut/secring.gpg<span class="string">' created</span></span><br><span class="line"><span class="string">gpg: keyring `/tmp/tmp7b1tsfut/pubring.gpg'</span> created</span><br><span class="line">gpg: requesting key 1118213C from hkp server keyserver.ubuntu.com</span><br><span class="line">gpg: /tmp/tmp7b1tsfut/trustdb.gpg: trustdb created</span><br><span class="line">gpg: key 1118213C: public key <span class="string">"Launchpad PPA for Graphics Drivers Team"</span> imported</span><br><span class="line">gpg: no ultimately trusted keys found</span><br><span class="line">gpg: Total number processed: 1</span><br><span class="line">gpg:               imported: 1  (RSA: 1)</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>
<p>如果添加 PPA 仓库报错的话，可以先 <code>remove</code> 掉，然后重新尝试：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo add-apt-repository --remove ppa:graphics-drivers/ppa</span><br><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa</span><br></pre></td></tr></table></figure>
<p>添加完 PPA 仓库，需要更新一下本地 apt-get 源：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br></pre></td></tr></table></figure>
<p>添加 PPA 仓库并且更新源后，先来识别显卡模型和查看源中推荐的驱动程序：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ ubuntu-drivers devices</span><br><span class="line">== /sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0 ==</span><br><span class="line">modalias : pci:v000010DEd00001401sv000019DAsd00001379bc03sc00i00</span><br><span class="line">model    : GM206 [GeForce GTX 960]</span><br><span class="line">vendor   : NVIDIA Corporation</span><br><span class="line">driver   : nvidia-415 - third-party free</span><br><span class="line">driver   : nvidia-384 - distro non-free</span><br><span class="line">driver   : nvidia-396 - third-party free</span><br><span class="line">driver   : nvidia-418 - third-party free</span><br><span class="line">driver   : nvidia-410 - third-party free</span><br><span class="line">driver   : xserver-xorg-video-nouveau - distro free builtin</span><br><span class="line">driver   : nvidia-390 - third-party free</span><br><span class="line">driver   : nvidia-430 - third-party free recommended</span><br></pre></td></tr></table></figure>
<p>–&gt; 开始安装：</p>
<p>首先你可以看到，PAA 仓库中提供有我们之前查询到的 390 版本的 Nvidia 驱动 。</p>
<p>当然，你可根据源中推荐的 Nvidia 版本进行安装（recommended）。这里我选择了 nvidia-384，它是支持 GTX 970 的一个稳定版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install nvidia-384</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装一些可能的依赖插件：</span></span><br><span class="line">$ sudo apt-get install mesa-common-dev</span><br><span class="line">$ sudo apt-get install freeglut3-dev</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>结论：</strong> 推荐使用 PPA 仓库安装 Nvidia 驱动，这是最简单的驱动安装方式。关于使用官方的驱动进行手动安装这里不介绍了。</p>
</blockquote>
<p>2) 重启系统让 GTX970 显卡驱动生效</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo reboot</span><br></pre></td></tr></table></figure>
<p>3) 驱动安装测试</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ watch -n -1 nvidia-smi</span><br><span class="line"></span><br><span class="line">% 显示如下信息表示显卡驱动安装成功（Ctrl + c 可退出查看状态）： </span><br><span class="line"></span><br><span class="line">Sat Jun  2 17:03:40 2018       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 384.130                Driver Version: 384.130                   |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  GeForce GTX 960     Off  | 00000000:01:00.0  On |                  N/A |</span><br><span class="line">| 36%   45C    P8    11W / 120W |   3863MiB /  4036MiB |      3%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0      1143      G   /usr/lib/xorg/Xorg                            94MiB |</span><br><span class="line">|    0      2070      G   compiz                                        42MiB |</span><br><span class="line">|    0     18635      G   /usr/lib/firefox/firefox                       1MiB |</span><br><span class="line">|    0     29337      C   ...naconda3/envs/tensorflow-3.5/bin/python  3710MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<p>4）确认重新安装的显卡驱动是否正常加载</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lshw -C display</span><br><span class="line">  *-display</span><br><span class="line">       description: VGA compatible controller</span><br><span class="line">       product: GM206 [GeForce GTX 960]</span><br><span class="line">       vendor: NVIDIA Corporation</span><br><span class="line">       physical id: 0</span><br><span class="line">       bus info: pci@0000:01:00.0</span><br><span class="line">       version: a1</span><br><span class="line">       width: 64 bits</span><br><span class="line">       clock: 33MHz</span><br><span class="line">       capabilities: pm msi pciexpress vga_controller bus_master cap_list rom</span><br><span class="line">       configuration: driver=nvidia latency=0</span><br><span class="line">       resources: irq:127 memory:f6000000-f6ffffff memory:e0000000-efffffff memory:f0000000-f1ffffff ioport:e000(size=128) memory:c0000-dffff</span><br></pre></td></tr></table></figure>
<p>可以发现，<code>driver=nvidia</code> 表明安装成功。</p>
<hr>
<h4 id="1-4-Nvidia-驱动卸载"><a href="#1-4-Nvidia-驱动卸载" class="headerlink" title="1.4 Nvidia 驱动卸载"></a>1.4 Nvidia 驱动卸载</h4><p>对于已经安装了 <code>Nvidia</code> 显卡驱动的服务器，可能由于其驱动版本过低，无法正常使用新版本的 CUDA。故，我们一般会将 <code>Nvidia</code> 显卡驱动更新到一个较新的版本。</p>
<p>前面我们已经知道如何安装全新的 <code>Nvidia</code> 显卡驱动，这里来看如何卸载服务器原有的显卡驱动程序：</p>
<p><strong>–&gt; 卸载低版本 Nvidia 显卡驱动</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get remove nvidia*</span><br></pre></td></tr></table></figure>
<p>上述我们已经卸载了系统中的 Nvidia 显卡驱动，接下来我们需要根据 <code>1.3 安装 Nvidia 驱动</code> 完成新的 <code>Nvidia</code> 显卡驱动的安装（注意此时千万不能重启，重新电脑可能会导致无法进入系统，安装好新驱动后再重启）。</p>
<hr>
<h4 id="1-5-Want-to-know-more"><a href="#1-5-Want-to-know-more" class="headerlink" title="1.5 Want to know more"></a>1.5 Want to know more</h4><p>好奇么？驱动安装不是都已经结束了，怎么还有一小节？？？黑脸</p>
<p>前面我们是基于搭载 GPU 独显的服务器安装 Ubuntu16.04 后开始驱动安装的。其实我们还可以先把 GPU 拿掉，然后在只有集显的服务器上先安装 Ubuntu16.04 ，接着按照上面的 （1） 过程安装 Nvidia 驱动，然后 <code>shutdown</code> 关机安装上 GPU 重启即可。</p>
<p>最后通过 （3）、（4）过程进行测试，会发现也可以。</p>
<p>这种方法可以避免驱动安装中的一些麻烦。</p>
<hr>
<p>在开始 CUDA 和 cuDNN 的安装之前，通过需要查看 <strong>Tensorflow &amp;&amp; NVIDIA 版本信息对照表</strong>，选择和TensorFlow [GPU Support] 版本兼容的 CUDA &amp;&amp; cuDNN 安装版本。</p>
<h3 id="2-下载和安装-CUDA-8-0"><a href="#2-下载和安装-CUDA-8-0" class="headerlink" title="2. 下载和安装 CUDA 8.0"></a>2. 下载和安装 CUDA 8.0</h3><p>在安装 CUDA 之前，Google 了一下，发现在 Ubuntu 下安装 CUDA8.0 非常常见，支持 GTX 970（其它版本 CUDA 安装类似），下面我们将以 CUDA8.0 的安装为样例：</p>
<p>注意，安装 CUDA8.0 之前请先确认系统中是否已安装有默认的 CUDA 版本？执行如下命令查看系统 CUDA 版本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ nvcc -V</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出如下信息表示当前系统已安装有 CUDA，安装目录见：/usr/local/</span></span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2016 NVIDIA Corporation</span><br><span class="line">Built on Tue_Jan_10_13:22:03_CST_2017</span><br><span class="line">Cuda compilation tools, release 8.0, V8.0.61</span><br><span class="line"></span><br><span class="line"><span class="comment"># 没有的话输出如下：</span></span><br><span class="line">The program <span class="string">'nvcc'</span> is currently not installed. You can install it by typing:</span><br><span class="line">sudo apt install nvidia-cuda-toolkit</span><br></pre></td></tr></table></figure>
<p>如果有，请先跳转至 <code>2.4 CUDA 卸载</code>，先卸载掉系统中已安装的 CUDA 版本，再开始下面的步骤。</p>
<h4 id="2-1-CUDA-下载"><a href="#2-1-CUDA-下载" class="headerlink" title="2.1 CUDA 下载"></a>2.1 CUDA 下载</h4><p>下载 CUDA 需要注册和登陆 NVIDIA 开发者账号，CUDA8 下载页面提供了很详细的系统选择和安装说明。这里选择了 Ubuntu16.04 系统 Runfile 安装方案，千万不要选择 deb 方案，前方无数坑：</p>
<p>这里，我们首先提供 <a href="https://developer.nvidia.com/cuda-80-ga2-download-archive" target="_blank" rel="noopener">CUDA 8.0 下载地址</a>，并且选择做如下平台设置（其它版本戳 <a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">这里</a>）:</p>
<p><img src="/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/cuda8_1.png" alt="avatar"></p>
<p>配置好平台设置后，进入下载界面。如下：</p>
<p><img src="/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/cuda8_2.png" alt="avatar"></p>
<hr>
<p>下载好的 <code>cuda_8.0.27_linux.run</code> 有 <code>1.4G</code>。下面按照 Nivdia 官方给出的方法安装 CUDA8：</p>
<h4 id="2-2-CUDA-安装"><a href="#2-2-CUDA-安装" class="headerlink" title="2.2 CUDA 安装"></a>2.2 CUDA 安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sh cuda_8.0.27_linux.run --tmpdir=/opt/temp/</span><br></pre></td></tr></table></figure>
<p>这里加了 <code>--tmpdir</code> 主要是因为直接运行 <code>sudo sh cuda_8.0.27_linux.run</code> 可能会提示空间不足的错误（如下），实际上是全新的电脑主机，硬盘足够大的（当报错后，你知道如何解决即可）。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Not enough space on parition mounted at /.</span><br><span class="line">Need 5091561472 bytes.</span><br><span class="line"></span><br><span class="line">Disk space check has failed. Installation cannot <span class="built_in">continue</span>.</span><br></pre></td></tr></table></figure>
<p><strong>–&gt; 执行 <code>sh cuda_8.0.27_linux.run</code> 后会有一系列提示让你确认，非常非常非常非常关键的地方是是否安装 <code>361</code> 这个低版本的驱动：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Install NVIDIA Accelerated Graphics Driver <span class="keyword">for</span> Linux-x86_64 361.62 ?</span><br></pre></td></tr></table></figure>
<p>答案必须是 <code>n</code>，否则之前安装的 <code>GTX970</code> 驱动就白费了，而且后续问题多多。</p>
<p><strong>–&gt; Next（详细安装步骤如下）:</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">Logging to /opt/temp//cuda_install_6583.log</span><br><span class="line">Using more to view the EULA.</span><br><span class="line">End User License Agreement</span><br><span class="line">--------------------------</span><br><span class="line">Preface</span><br><span class="line">-------</span><br><span class="line">The following contains specific license terms and conditions</span><br><span class="line"><span class="keyword">for</span> four separate NVIDIA products. By accepting this</span><br><span class="line">agreement, you agree to comply with all the terms and</span><br><span class="line">conditions applicable to the specific product(s) included</span><br><span class="line">herein.</span><br><span class="line"></span><br><span class="line">Do you accept the previously <span class="built_in">read</span> EULA?</span><br><span class="line">accept/decline/quit: accept</span><br><span class="line"></span><br><span class="line">Install NVIDIA Accelerated Graphics Driver <span class="keyword">for</span> Linux-x86_64 361.62?</span><br><span class="line">(y)es/(n)o/(q)uit: n</span><br><span class="line"></span><br><span class="line">Install the CUDA 8.0 Toolkit?</span><br><span class="line">(y)es/(n)o/(q)uit: y</span><br><span class="line"></span><br><span class="line">Enter Toolkit Location</span><br><span class="line">[ default is /usr/<span class="built_in">local</span>/cuda-8.0 ]:</span><br><span class="line"></span><br><span class="line">Do you want to install a symbolic link at /usr/<span class="built_in">local</span>/cuda?</span><br><span class="line">(y)es/(n)o/(q)uit: y</span><br><span class="line"></span><br><span class="line">Install the CUDA 8.0 Samples?</span><br><span class="line">(y)es/(n)o/(q)uit: y</span><br><span class="line"></span><br><span class="line">Enter CUDA Samples Location</span><br><span class="line">[ default is /home/textminer ]:</span><br><span class="line"></span><br><span class="line">Driver: Not Selected</span><br><span class="line"></span><br><span class="line">Installing the CUDA Toolkit <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0 ...</span><br><span class="line">Installing the CUDA Samples <span class="keyword">in</span> /home/textminer ...</span><br><span class="line">Copying samples to /home/textminer/NVIDIA_CUDA-8.0_Samples now...</span><br><span class="line">Finished copying samples.</span><br><span class="line">	</span><br><span class="line">===========</span><br><span class="line">= Summary =</span><br><span class="line">===========</span><br><span class="line"></span><br><span class="line">Driver: Not Selected</span><br><span class="line">Toolkit: Installed <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0</span><br><span class="line">Samples: Installed <span class="keyword">in</span> /home/textminer</span><br><span class="line"></span><br><span class="line">Please make sure that</span><br><span class="line">- PATH includes /usr/<span class="built_in">local</span>/cuda-8.0/bin</span><br><span class="line">- LD_LIBRARY_PATH includes /usr/<span class="built_in">local</span>/cuda-8.0/lib64, or, add /usr/<span class="built_in">local</span>/cuda-8.0/lib64 to /etc/ld.so.conf and run ldconfig as root</span><br><span class="line"></span><br><span class="line">To uninstall the CUDA Toolkit, run the uninstall script <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0/bin</span><br><span class="line"></span><br><span class="line">Please see CUDA_Installation_Guide_Linux.pdf <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0/doc/pdf <span class="keyword">for</span> detailed information on setting up CUDA.</span><br><span class="line"></span><br><span class="line">***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required <span class="keyword">for</span> CUDA 8.0 functionality to work.</span><br><span class="line">To install the driver using this installer, run the following <span class="built_in">command</span>, replacing with the name of this run file:</span><br><span class="line">sudo .run -silent -driver</span><br><span class="line"></span><br><span class="line">Logfile is /opt/temp//cuda_install_6583.log</span><br></pre></td></tr></table></figure>
<p><strong>–&gt; 配置环境变量：</strong></p>
<p>安装完毕后，需要再声明一下环境变量，并将其写入到 <code>~/.bashrc</code> 的尾部:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/cuda-8.0/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda-8.0/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure>
<p>更新 <code>~/.bashrc</code> 配置文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：如果是已经安装了 NVIDIA 和 CUDA 的云服务器，还需要添加环境变量才可以使用。</p>
</blockquote>
<p>如果环境变量设置错误，<code>PATH</code> 值被覆盖了，这会导致 <code>ls、make</code> 等基本命令都用不了，提示 <code>xxx: command not found</code>。后来查阅资料，通过输入以下语句，可还原 <code>PATH</code> 变量值进行恢复（恢复至默认 <code>PATH</code> 值）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/sbin:/usr/<span class="built_in">local</span>/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin</span><br></pre></td></tr></table></figure>
<hr>
<p>至此，CUDA8.0的安装其实已经完成了！！！但是请注意安装过程中这里可能有报错（<code>missing recommended</code>）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Driver: Not Selected</span><br><span class="line">Toolkit: Installed <span class="keyword">in</span> /usr/<span class="built_in">local</span>/cuda-8.0</span><br><span class="line">Samples: Installed <span class="keyword">in</span> /home/zhou, but missing recommended</span><br></pre></td></tr></table></figure>
<p>不注意的话，会导致后续 <code>CUDA</code> 测试（ <code>nbody</code> 样例）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span>  ~/NVIDIA_CUDA-8.0_Samples/5_Simulations/nbody  </span><br><span class="line">$ make </span><br><span class="line">$ ./nbody</span><br></pre></td></tr></table></figure>
<p>即在 CUDA 上运行 <code>nbody</code> 样例，<code>make</code> 部分报错：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; WARNING - libGLU.so not found, refer to CUDA Getting Started Guide <span class="keyword">for</span> how to find and install them. &lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt; WARNING - libX11.so not found, refer to CUDA Getting Started Guide <span class="keyword">for</span> how to find and install them. &lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt; WARNING - gl.h not found, refer to CUDA Getting Started Guide <span class="keyword">for</span> how to find and install them. &lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt; WARNING - glu.h not found, refer to CUDA Getting Started Guide <span class="keyword">for</span> how to find and install them. &lt;&lt;&lt;</span><br><span class="line">&gt;&gt;&gt; WARNING - Xlib.h not found, refer to CUDA Getting Started Guide <span class="keyword">for</span> how to find and install them. &lt;&lt;&lt;</span><br><span class="line">[@] /usr/<span class="built_in">local</span>/cuda-8.0/bin/nvcc -ccbin g++ -I../../common/inc -m64 -ftz=<span class="literal">true</span> -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_60,code=compute_60 -o bodysystemcuda.o -c bodysystemcuda.cu</span><br><span class="line">[@] /usr/<span class="built_in">local</span>/cuda-8.0/bin/nvcc -ccbin g++ -I../../common/inc -m64 -ftz=<span class="literal">true</span> -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_60,code=compute_60 -o nbody.o -c nbody.cpp</span><br><span class="line">[@] /usr/<span class="built_in">local</span>/cuda-8.0/bin/nvcc -ccbin g++ -I../../common/inc -m64 -ftz=<span class="literal">true</span> -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_60,code=compute_60 -o render_particles.o -c render_particles.cpp</span><br><span class="line">[@] /usr/<span class="built_in">local</span>/cuda-8.0/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_20,code=sm_20 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_60,code=compute_60 -o nbody bodysystemcuda.o nbody.o render_particles.o -L/usr/lib/nvidia-367 -lGL -lGLU -lX11 -lglut</span><br><span class="line">[@] mkdir -p ../../bin/x86_64/linux/release</span><br><span class="line">[@] cp nbody ../../bin/x86_64/linux/release</span><br></pre></td></tr></table></figure>
<p><strong>–&gt; 解决方案：</strong>从 <code>make</code> 报错，我们知道缺少一些编译库，下面我们来安装这些库文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libgl1-mesa-glx libglu1-mesa libglu1-mesa-dev libglfw3-dev libgles2-mesa-dev</span><br><span class="line"></span><br><span class="line">$ GLPATH=/usr/lib make</span><br></pre></td></tr></table></figure>
<p><strong>–&gt; 成功之后会显示：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; Windowed mode</span><br><span class="line">&gt; Simulation data stored <span class="keyword">in</span> video memory</span><br><span class="line">&gt; Single precision floating point simulation</span><br><span class="line">&gt; 1 Devices used <span class="keyword">for</span> simulation</span><br><span class="line">gpuDeviceInit() CUDA Device [0]: <span class="string">"GeForce GTX 1080</span></span><br><span class="line"><span class="string">&gt; Compute 6.1 CUDA device: [GeForce GTX 1080]</span></span><br><span class="line"><span class="string">number of bodies = 256000</span></span><br><span class="line"><span class="string">256000 bodies, total time for 10 iterations: 2291.469 ms</span></span><br><span class="line"><span class="string">= 286.000 billion interactions per second</span></span><br><span class="line"><span class="string">= 5719.998 single-precision GFLOP/s at 20 flops per interaction</span></span><br></pre></td></tr></table></figure>
<hr>
<h4 id="2-3-CUDA-测试"><a href="#2-3-CUDA-测试" class="headerlink" title="2.3 CUDA 测试"></a>2.3 CUDA 测试</h4><p>1）NVCC</p>
<pre><code>$ nvcc –V
</code></pre><p>输出信息显示如下：</p>
<p><img src="/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/nvcc.png" alt="avatar"></p>
<p>2）显示 GPU 信息</p>
<p>–&gt; 进入 <code>cd NVIDIA_CUDA-8.0_Sample/1_Utilities/deviceQuery</code> 目录：</p>
<p>–&gt; 执行：<code>make</code>；</p>
<p>–&gt; 执行：<code>./deviceQuery</code>，结果如下：</p>
<p><img src="/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/deviceQuery.png" alt="avatar"></p>
<p>3）nbody 测试见 2.2 CUDA 安装。</p>
<p>恭喜你！至此，CUDA 安装已经完成！！！</p>
<hr>
<h4 id="2-4-CUDA-卸载"><a href="#2-4-CUDA-卸载" class="headerlink" title="2.4 CUDA 卸载"></a>2.4 CUDA 卸载</h4><p>通过前面的介绍，我们了解了如何在服务器上安装 CUDA 应用。事实上，很多时候我们的服务器本身已经默认安装了某个版本的 CUDA，而搭建 <code>TensorFlow GPU Support</code> 环境要求安装特定版本的 CUDA。故这一小节我们来看如何卸载服务器中已安装的 CUDA。</p>
<p>分别针对 <code>.deb</code> 和 <code>.run</code> 两种不同的安装方式（卸载方法不同），这里提供两种方式来卸载系统原有的 CUDA：</p>
<p><strong>1）.run 方法卸载</strong></p>
<p>执行如下命令进行自动卸载（以 <code>cuda-8.0</code> 卸载为例）：</p>
<pre><code>$ sudo /usr/local/cuda-8.0/bin/uninstall_cuda-8.0.pl
</code></pre><p>有上述卸载文件 <code>uninstall_cuda-8.0.pl</code> 就说明是之前是用 <code>.run</code> 文件安装的，没有则是用 <code>.deb</code> 文件安装的，可以使用第二种方法进行卸载：</p>
<p><strong>2）.deb 方法卸载</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get remove cuda</span><br><span class="line"></span><br><span class="line">$ sudo apt-get autoclean</span><br><span class="line"></span><br><span class="line">$ sudo apt-get remove cuda*</span><br></pre></td></tr></table></figure>
<p><strong>3）清空残留文件</strong></p>
<p>最后，将当前目录切换至 <code>/usr/local/</code> 下，查看是否还残留有未删除干净的 CUDA 相关文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/</span><br><span class="line">$ ls</span><br><span class="line"></span><br><span class="line">% 存在残留文件则删除：</span><br><span class="line">sudo rm -rf cuda-8.0</span><br></pre></td></tr></table></figure>
<hr>
<p>下面让我们来看 CUDNN 的安装：</p>
<h3 id="3-CUDNN-5-1-安装"><a href="#3-CUDNN-5-1-安装" class="headerlink" title="3. CUDNN 5.1 安装"></a>3. CUDNN 5.1 安装</h3><h4 id="3-1-CUDNN-下载"><a href="#3-1-CUDNN-下载" class="headerlink" title="3.1 CUDNN 下载"></a>3.1 CUDNN 下载</h4><p>CUDNN 全称 <code>CUDA Deep Neural Network library</code>，是 NVIDIA 专门针对深度神经网络设计的一套 GPU 计算加速库，被广泛用于各种深度学习框架，例如 <code>Caffe, TensorFlow, Theano, Torch, CNTK</code>等。</p>
<p>从 <a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener">Nvidia 官方</a> 下载链接选择一个版本，不过下载 cuDNN 前同样需要登录甚至填写一个简单的调查问卷，链接界面如下：</p>
<p><img src="/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/cudnn.png" alt="avatar"></p>
<h4 id="3-2-CUDNN-安装"><a href="#3-2-CUDNN-安装" class="headerlink" title="3.2 CUDNN 安装"></a>3.2 CUDNN 安装</h4><p>安装 CUDNN 比较简单，解压后把相应的文件拷贝到对应的 CUDA 目录下即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ tar -zxvf cudnn-8.0-linux-x64-v5.1.tgz</span><br><span class="line"></span><br><span class="line">cuda/include/cudnn.h</span><br><span class="line">cuda/lib64/libcudnn.so</span><br><span class="line">cuda/lib64/libcudnn.so.5</span><br><span class="line">cuda/lib64/libcudnn.so.5.0.5</span><br><span class="line">cuda/lib64/libcudnn_static.a</span><br><span class="line"></span><br><span class="line">$ sudo cp cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/include/</span><br><span class="line">$ sudo cp cuda/lib64/libcudnn* /usr/<span class="built_in">local</span>/cuda/lib64/</span><br><span class="line">$ sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/include/cudnn.h</span><br><span class="line">$ sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure>
<p>可以发现，cuDNN 中的 5 个文件（全部），在 <code>/usr/local/cuda/include/ &amp;&amp; /usr/local/cuda/lib64/</code> 中找不到相同文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls /usr/<span class="built_in">local</span>/cuda/lib64/ |grep libcudnn</span><br><span class="line">$ ls /usr/<span class="built_in">local</span>/cuda/include/ |grep cudnn</span><br></pre></td></tr></table></figure>
<p>cuDNN 其实就是 CUDA 的扩展计算库，把 cuDNN 相关库文件添加 CUDA 里，不会对CUDA造成其他影响，即所谓的插入式设计。这保证了当前系统环境中可以存在多个版本的 cuDNN。</p>
<h4 id="3-3-CUDNN-升级"><a href="#3-3-CUDNN-升级" class="headerlink" title="3.3 CUDNN 升级"></a>3.3 CUDNN 升级</h4><p>这里，假设一下：上面我们已经完成了 <code>cuDNN v5.1 for CUDA8.0</code> 的安装。事实上，我们需要的是 <code>cuDNN v6.0 for CUDA8.0</code> 计算加速包，那么我们如何将 <code>cuDNN</code> 版本升级到 <code>cuDNN v6.0</code> 呢？</p>
<p>其实很简单。下载 <code>cuDNN v6.0</code> 安装包 <code>cudnn-8.0-linux-x64-v6.0.tgz</code>、解压以及使用 <code>cuDNN v6.0</code> 库文件覆盖 <code>CUDA</code> 中的 <code>cuDNN v5.1</code> 库文件即可。详细步骤如下：</p>
<pre><code>$ tar -zxvf cudnn-8.0-linux-x64-v6.0.tgz

cuda/include/cudnn.h
cuda/lib64/libcudnn.so
cuda/lib64/libcudnn.so.6
cuda/lib64/libcudnn.so.6.0.6
cuda/lib64/libcudnn_static.a

$ rm /usr/local/cuda/include/cudnn.h
$ rm /usr/local/cuda/lib64/libcudnn*

$ sudo cp cuda/include/cudnn.h /usr/local/cuda/include/
$ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/
$ sudo chmod a+r /usr/local/cuda/include/cudnn.h
$ sudo chmod a+r /usr/local/cuda/lib64/libcudnn*
</code></pre><p>至此，CUDA 8.0 以及 CUDNN 5.1 安装完成！接下来就可以开始 Tensorflow GPU Enabled 的安装。</p>
<hr>
<h3 id="4-Anaconda-Tensorflow-GPU-安装"><a href="#4-Anaconda-Tensorflow-GPU-安装" class="headerlink" title="4. Anaconda + Tensorflow-GPU 安装"></a>4. Anaconda + Tensorflow-GPU 安装</h3><p>这里我们推荐使用 Anconda 来安装 Tensorflow-GPU。</p>
<h4 id="4-1-Conda-Envs-install-TensorFlow"><a href="#4-1-Conda-Envs-install-TensorFlow" class="headerlink" title="4.1 Conda Envs install TensorFlow"></a>4.1 Conda Envs install TensorFlow</h4><p>通过 Anaconda 安装 Tensorflow 详细过程见博文 <a href="https://www.orangeshare.cn/TensorFlow/Centos6%EF%BC%887%EF%BC%89-Ubuntu-在线搭建-Anaconda3-Tensorflow-开发环境/" target="_blank" rel="noopener">Centos6（7）/Ubuntu 在线搭建 Anaconda &amp; Tensorflow 开发环境</a>中【<strong>2.4 使用 Anaconda 安装</strong>】小节（Ubuntu14.04/16.04 环境下已测试），篇幅原因不赘述。</p>
<p>对于其它方式 TensorFlow 的安装可以参见博文中的其它章节。</p>
<h4 id="4-2-TensorFlow-导入测试"><a href="#4-2-TensorFlow-导入测试" class="headerlink" title="4.2 TensorFlow 导入测试"></a>4.2 TensorFlow 导入测试</h4><p>正常情况，如果安装的 Python、TensorFlow 版本正确，<code>import tensorflow as tf</code> 时，无报错。</p>
<p><strong><code>import tensorflow as tf</code> 时，可能产生报错：</strong></p>
<pre><code>libcudnn.so.6:cannot open sharedobjectfile:No such file or directory
</code></pre><p><strong>问题解释：</strong></p>
<p>根据错误代码，应该是找不到 <code>libcudnn.so.6</code>。到指定文件夹下发现只有 <code>5.0</code> 和 <code>8.0</code> 的版本，没有 <code>6.0</code>，查找原因是因为当前已经是 <code>1.3</code> 版本，而 <code>tensorflow-gpu1.3</code> 已经开始去找 <code>cudnn6</code> 了（也就是说是用 <code>cudnn6</code> 编译的）…所以需要换到 <code>tensorflow-gpu1.2</code> 版本，就解决问题了。</p>
<p><strong>解决方法：</strong></p>
<p>先卸载掉之前安装的 tensorflow 环境或 tensorflow 环境中安装的 tensorflow：</p>
<pre><code>$ conda remove –n tensorflow-3.5 –all
$ conda create –n tensorflow-3.5 python=3.5
$ pip install tensorflow-gpu==1.2
</code></pre><h4 id="4-3-GPU-运算测试"><a href="#4-3-GPU-运算测试" class="headerlink" title="4.3 GPU 运算测试"></a>4.3 GPU 运算测试</h4><p>测试代码：<code>gpu_test.py</code>。这里以一个简单的向量加法为例来测试 TensorFlow [GPU Support] 环境：</p>
<pre><code>import tensorflow as tf

a = tf.constant([1.0,2.0,3.0], shape=[3], name=”a”)
b = tf.constant([1.0,2.0,3.0], shape=[3], name=”b”)
result = a + b

# 通过 log_device_placement 参数来输出运行每一个运算的设备：
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))

print (sess.run(result))
</code></pre><p><strong>结果输出信息如下：</strong></p>
<p>[3.1] 在没有 GPU 的机器上运行上述代码，可以得到如下输出：</p>
<pre><code>Device mapping: no known devices
add :/job:localhost/replica:0/task:0/cpu:0
a : /job:localhost/replica:0/task:0/cpu:0
b : /job:localhost/replica:0/task:0/cpu:0
</code></pre><p>[3.2] 配置好 GPU 环境的 TensorFlow 中，没有明确制定运行设备的话，TensorFlow 会优先选择 GPU 设备运行，会得到如下结果：</p>
<pre><code>Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce GTX 960, pci bus id: 0000:01:00.0
2018-02-04 13:01:33.343286: I tensorflow/core/common_runtime/direct_session.cc:265] Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce GTX 960, pci bus id: 0000:01:00.0

add: (Add): /job:localhost/replica:0/task:0/gpu:0
2018-02-04 13:01:33.343948: I tensorflow/core/common_runtime/simple_placer.cc:847] add: (Add)/job:localhost/replica:0/task:0/gpu:0
b: (Const): /job:localhost/replica:0/task:0/gpu:0
2018-02-04 13:01:33.343980: I tensorflow/core/common_runtime/simple_placer.cc:847] b: (Const)/job:localhost/replica:0/task:0/gpu:0
a: (Const): /job:localhost/replica:0/task:0/gpu:0
2018-02-04 13:01:33.343997: I tensorflow/core/common_runtime/simple_placer.cc:847] a: (Const)/job:localhost/replica:0/task:0/gpu:0
[2. 4. 6.]
</code></pre><p>自此，<code>Ubuntu16.04 + Nvidia GTX 970 + CUDA8.0 + CUDNN + Anaconda3 + Tensorflow1.2</code> 深度学习环境搭建完成。</p>
<hr>
<h3 id="5-I-Want-To-Know-More"><a href="#5-I-Want-To-Know-More" class="headerlink" title="5. I Want To Know More"></a>5. I Want To Know More</h3><h4 id="5-1-NVIDIA-驱动相关"><a href="#5-1-NVIDIA-驱动相关" class="headerlink" title="5.1 NVIDIA 驱动相关"></a>5.1 NVIDIA 驱动相关</h4><p><strong>1）nvidia-smi</strong></p>
<p>英伟达系统管理接口（<code>NVIDIA System Management Interface</code>, 简称 <code>nvidia-smi</code>），属于命令行管理组件，旨在帮助管理和监控 <code>NVIDIA GPU</code> 设备。</p>
<p>执行 <code>nvidia-smi</code> 命令可以查看当前系统安装的 NVIDIA 驱动信息以及 GPU 使用情况，显示如下：</p>
<pre><code>$ root@Ubuntu:~# nvidia-smi

Thu Feb 28 15:50:39 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla P4            On   | 00000000:00:07.0 Off |                    0 |
| N/A   30C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</code></pre><p>可以看出：驱动版本（NVIDIA-SMI 390.46）、显卡型号（Tesla P4）、内存（7611MiB：8G）以及 GPU 使用率（GPU-Util  Compute M.： 0% Default）等。</p>
<p><code>nvidia-smi</code> 配合 <code>watch -n</code> 一起使用，可用于动态查看 <code>GPU</code> 使用情况：</p>
<pre><code>$ watch -n -1 nvidia-smi 
</code></pre><p><strong>2）lspci</strong></p>
<p>查看服务器集成显卡信息：</p>
<pre><code>$ lspci | grep VGA
00:02.0 VGA compatible controller: Cirrus Logic GD 5446
</code></pre><p>查看服务器 NVIDIA 显卡信息：</p>
<pre><code>$ lspci | grep NVIDIA
00:07.0 3D controller: NVIDIA Corporation Device 1bb3 (rev a1)
</code></pre><p><strong>3）集显与独显的切换</strong></p>
<p>NVIDIA 还提供了用于切换显卡的命令。例如，查看当前使用的显卡：</p>
<pre><code>$ sudo prime-select query
</code></pre><p>如何切换 nvidia 显卡：</p>
<pre><code>$ sudo prime-select nvidia
</code></pre><p>如何切换 intel 显卡：</p>
<pre><code>$ sudo prime-select intel
</code></pre><hr>
<h4 id="5-2-CUDA-多版本共存和实时切换"><a href="#5-2-CUDA-多版本共存和实时切换" class="headerlink" title="5.2 CUDA 多版本共存和实时切换"></a>5.2 CUDA 多版本共存和实时切换</h4><p>事实上，很多情况下我们需要多 CUDA 版本兼容存在于服务器系统中，并且可以很容易地在不同版本之间进行迅速切换。请参见如下场景：</p>
<ol>
<li><p>多人共享使用当前服务器，由于使用的 TensorFlow 框架版本不同，所需要的 CUDA 版本也不同。此时，系统需要存在多个版本的 CUDA；</p>
</li>
<li><p>之前搭建 TensorFlow 环境使用的是 <code>CUDA8.0</code> 和 <code>cuDNN5.1</code>，当我们需要在 TensorFlow 环境中兼容其它深度学习环境时（搭建 <code>TensorFlow + Pytorch</code> 环境），<code>Pytroch GPU Support</code> 可能需要更高版本的 <code>CUDA</code> 以及 <code>cuDNN</code>。此时，升级 <code>CUDA</code> 以及 <code>cuDNN</code> 版本以适应 <code>TensorFlow + Pytorch</code> 环境是必要的。</p>
</li>
</ol>
<p>这一部分，我们会以同时安装 <code>cuda-8.0</code> 和 <code>cuda-9.0</code> 版本为例进行说明。</p>
<h5 id="5-2-1-CUDA-多版本共存"><a href="#5-2-1-CUDA-多版本共存" class="headerlink" title="5.2.1 CUDA 多版本共存"></a>5.2.1 CUDA 多版本共存</h5><p><strong>1）CUDA 的下载与安装方法选择</strong></p>
<p>对于 <code>cuda-8.0</code> 和 <code>cuda-9.0</code>，无论先安装哪个版本，都一样。上面已经安装过 <code>cuda-8.0</code> 了，这里，我们将补充安装 <code>cuda-9.0</code> 版本。</p>
<p>下载 CUDA 需要注册和登陆 NVIDIA 开发者账号。这里，我们首先给出 <a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">CUDA 版本库地址</a> 供选择下载目标版本 CUDA 安装包，版本库页面如下：</p>
<p><img src="/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/cuda_download.png" alt="avatar"></p>
<p>通过 CUDA 版本库地址 进入 CUDA9.0 下载页面后，可以看到这里提供了很详细的系统选择和安装说明。这里选择了 <code>Ubuntu16.04</code> 系统 <code>Runfile</code> 安装方案，（千万不要选择 <code>deb</code> 方案，否则前方无数坑）,下载界面如下：</p>
<p><img src="/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/Img/cuda9.jpg" alt="avatar"></p>
<p>下载完成之后，进入到 CUDA9.0 安装包（<code>cuda_9.0.176_384.81_linux.run</code>）所在目录运行如下命令即可开始进行安装，详细安装过程讲解如下：</p>
<pre><code>$ sudo sh cuda_9.0.176_384.81_linux.run

Using more to view the EULA.
End User License Agreement
--------------------------
Preface
-------
The following contains specific license terms and conditions
for four separate NVIDIA products. By accepting this
agreement, you agree to comply with all the terms and
conditions applicable to the specific product(s) included
herein.

# 接受安装协议：
Do you accept the previously read EULA?
accept/decline/quit: accept

# 询问是否重新安装显卡驱动，这里一定要选择 `n`，否则最初安装的显卡驱动会被覆盖产生出错：
Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81?
(y)es/(n)o/(q)uit: n

Install the CUDA 9.0 Toolkit?
(y)es/(n)o/(q)uit: y

# 定义安装目录（一般默认回车即可，即安装在 `/usr/local/cuda-9.0` 目录下）,
Enter Toolkit Location
[ default is /usr/local/cuda-9.0 ]: 

# 询问是否将 `cuda-9.0` 安装目录通过软连接的方式 link 到 `/usr/local/cuda`？【 yes or no 】 均可。
# 系统当前启用的 `cuda` 为哪个版本？取决于哪个版本的 CUDA 安装目录被链接到 `/usr/local/cuda` 上。
# 对于首次安装 CUDA，肯定是需要建立软连接的（yes）；对于安装额外版本的 CUDA，【 yes or no 】 需要根据是否启动新版本 CUDA 决定。
Do you want to install a symbolic link at /usr/local/cuda? 
(y)es/(n)o/(q)uit: n

# 询问是否安装样例，可用于后续检测是否安装成功：
Install the CUDA 9.0 Samples?
(y)es/(n)o/(q)uit: n

# 定义样例安装目录：
Enter CUDA Samples Location
[ default is /root ]: /home/textminer

# *** 安装信息显示 **** #
Driver: Not Selected

Installing the CUDA Toolkit in /usr/local/cuda-9.0 ...
Installing the CUDA Samples in /home/textminer ...
Copying samples to /home/textminer/NVIDIA_CUDA-9.0_Samples now...
Finished copying samples.

===========
= Summary =
===========

Driver: Not Selected
Toolkit: Installed in /usr/local/cuda-9.0
Samples: Installed in /home/textminer

Please make sure that
- PATH includes /usr/local/cuda-9.0/bin
- LD_LIBRARY_PATH includes /usr/local/cuda-9.0/lib64, or, add /usr/local/cuda-9.0/lib64 to /etc/ld.so.conf and run ldconfig as root

To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-9.0/bin

Please see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-9.0/doc/pdf for detailed information on setting up CUDA.

***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 361.00 is required for CUDA 9.0 functionality to work.
To install the driver using this installer, run the following command, replacing with the name of this run file:
sudo .run -silent -driver

Logfile is /opt/temp//cuda_install_6583.log
</code></pre><p><strong>2）配置 CUDA 环境变量</strong></p>
<p>在配置文件 <code>~/.bashrc</code> 文件末尾添加如下内容：</p>
<pre><code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64
export PATH=$PATH:/usr/local/cuda/bin
export CUDA_HOME=$CUDA_HOME:/usr/local/cuda
</code></pre><p>注意，安装过程中是否创建 <code>symbolic link</code> 是关键。首次安装，选 【yes】；安装额外的版本，选 【no】。自此，我们已经成功完成了 <code>cuda-8.0</code> 和 <code>cuda-9.0</code> 的安装。下面我们来看如何迅速完成 CUDA 版本的切换：</p>
<hr>
<h5 id="5-2-2-CUDA-版本实时切换"><a href="#5-2-2-CUDA-版本实时切换" class="headerlink" title="5.2.2 CUDA 版本实时切换"></a>5.2.2 CUDA 版本实时切换</h5><p>通过上文可知，当我们安装了多个版本的 CUDA 之后，CUDA 一般会被安装到 <code>/usr/local/</code> 目录（或你自己的自定义目录）下。查看一下当前目录下的文件：</p>
<pre><code>$ cd /usr/local
$ ls
bin  cuda  cuda-8.0  cuda-9.0 etc  games ......
</code></pre><p>上述 <code>cuda-8.0</code> 和 <code>cuda-9.0</code> 是系统中已安装的 CUDA 版本，而 <code>cuda</code> 就是我们上面创建的 <code>symbolic link</code>。<code>cuda</code> 指向系统当前正在启用的 <code>cuda</code> 版本，方便了我们切换 <code>cuda</code> 版本，可以让我们不用每次都去 <code>~/.bashrc</code> 修改环境变量的值（<code>cuda-8.0</code> or <code>cuda-9.0</code>）。</p>
<p>我们先来查看当前 <code>cuda</code> 软链接指向的哪个 <code>cuda</code> 版本:</p>
<pre><code>$ stat cuda
  File: &apos;cuda&apos; -&gt; &apos;/usr/local/cuda-8.0&apos;
  Size: 19            Blocks: 0          IO Block: 4096   symbolic link
Device: 807h/2055d    Inode: 133904      Links: 1
Access: (0777/lrwxrwxrwx)  Uid: (    0/    root)   Gid: (    0/    root)
Access: 2019-02-28 10:44:36.494902702 +0800
Modify: 2018-02-03 10:52:47.543432671 +0800
Change: 2018-02-03 10:52:47.543432671 +0800
 Birth: -
</code></pre><p>可以看到，<code>cuda&#39; -&gt; &#39;/usr/local/cuda-8.0</code>，此时系统当前正在启用的 <code>cuda</code> 版本为 <code>cuda-8.0</code>。</p>
<p>那么，我们如何快速完成 <code>cuda-9.0</code> 的版本呢？其实很简单：</p>
<pre><code># 查看系统当前启用的 CUDA 版本：
$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Tue_Jan_10_13:22:03_CST_2017
Cuda compilation tools, release 8.0, V8.0.61

# 从 `cuda8.0` 切换到 `cuda9.0`: 
$ rm -rf /usr/local/cuda
$ sudo ln -s /usr/local/cuda-9.0/ /usr/local/cuda/

$ nvcc --version    
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Tue_Jan_10_13:22:03_CST_2018
Cuda compilation tools, release 9.0, V9.0.176
</code></pre><hr>
<h3 id="Tensorflow-amp-amp-NVIDIA-版本信息对照表"><a href="#Tensorflow-amp-amp-NVIDIA-版本信息对照表" class="headerlink" title="Tensorflow &amp;&amp; NVIDIA 版本信息对照表"></a>Tensorflow &amp;&amp; NVIDIA 版本信息对照表</h3><h4 id="For-Windows"><a href="#For-Windows" class="headerlink" title="For Windows"></a>For Windows</h4><p>官方经过测试的 Tensorflow &amp;&amp; CUDA &amp;&amp; cuDNN 版本对应关系（持续更新）：<a href="https://tensorflow.google.cn/install/source_windows#tested_build_configurations" target="_blank" rel="noopener">https://tensorflow.google.cn/install/source_windows#tested_build_configurations</a> 。</p>
<blockquote>
<p>Windows</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">TensorFlow 版本：         CPU/GPU:   Python 版本:    编译器:                 构建工具:           CUDNN:  CUDA:</span><br><span class="line">----------------------------------------------------------------------------------------------------------------------</span><br><span class="line">tensorflow-1.13.0         CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.13.0     GPU           3.5-3.6      MSVC 2015 update 3     Bazel 0.15.0        7        9</span><br><span class="line">tensorflow-1.12.0         CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.12.0     GPU           3.5-3.6      MSVC 2015 update 3     Bazel 0.15.0        7        9</span><br><span class="line">tensorflow-1.11.0         CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.11.0     GPU           3.5-3.6      MSVC 2015 update 3     Bazel 0.15.0        7        9</span><br><span class="line">tensorflow-1.10.0         CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.10.0     GPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        7        9</span><br><span class="line">tensorflow-1.9.0          CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.9.0      GPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        7        9</span><br><span class="line">tensorflow-1.8.0          CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.8.0      GPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        7        9</span><br><span class="line">tensorflow-1.7.0          CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.7.0      GPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        7        9</span><br><span class="line">tensorflow-1.6.0          CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.6.0      GPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        7        9</span><br><span class="line">tensorflow-1.5.0          CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.5.0      GPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        7        9</span><br><span class="line">tensorflow-1.4.0          CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.4.0      GPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        6        8</span><br><span class="line">tensorflow-1.3.0          CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.3.0      GPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        6        8</span><br><span class="line">tensorflow-1.2.0          CPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.2.0      GPU           3.5-3.6      MSVC 2015 update 3     Cmake v3.6.3        5.1      8</span><br><span class="line">tensorflow-1.1.0          CPU           3.5          MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.1.0      GPU           3.5          MSVC 2015 update 3     Cmake v3.6.3        5.1      8</span><br><span class="line">tensorflow-1.0.0          CPU           3.5          MSVC 2015 update 3     Cmake v3.6.3        N        N</span><br><span class="line">tensorflow_gpu-1.0.0      GPU           3.5          MSVC 2015 update 3     Cmake v3.6.3        5.1      8</span><br></pre></td></tr></table></figure>
<h4 id="For-Linux-amp-amp-Mac"><a href="#For-Linux-amp-amp-Mac" class="headerlink" title="For Linux &amp;&amp; Mac"></a>For Linux &amp;&amp; Mac</h4><p>官方经过测试的 Tensorflow &amp;&amp; CUDA &amp;&amp; cuDNN 版本对应关系（持续更新）：<a href="https://tensorflow.google.cn/install/source#tested_build_configurations" target="_blank" rel="noopener">https://tensorflow.google.cn/install/source#tested_build_configurations</a> 。</p>
<blockquote>
<p>Linux</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">TensorFlow 版本：        CPU/GPU:    Python 版本:     编译器:       构建工具:        CUDNN:   CUDA:</span><br><span class="line">----------------------------------------------------------------------------------------------------------------------</span><br><span class="line">tensorflow-1.13.1          CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.19.2        N       N</span><br><span class="line">tensorflow_gpu-1.13.1      GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.15.0        7.4     10.0</span><br><span class="line">tensorflow-1.12.0          CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.15.0        N       N</span><br><span class="line">tensorflow_gpu-1.12.0      GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.15.0        7       9</span><br><span class="line">tensorflow-1.11.0          CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.15.0        N       N</span><br><span class="line">tensorflow_gpu-1.11.0      GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.15.0        7       9</span><br><span class="line">tensorflow-1.10.0          CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.15.0        N       N</span><br><span class="line">tensorflow_gpu-1.10.0      GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.15.0        7       9</span><br><span class="line">tensorflow-1.9.0           CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.11.0        N       N</span><br><span class="line">tensorflow_gpu-1.9.0       GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.11.0        7       9</span><br><span class="line">tensorflow-1.8.0           CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.10.0        N       N</span><br><span class="line">tensorflow_gpu-1.8.0       GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.10.0        7       9</span><br><span class="line">tensorflow-1.7.0           CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.10.0        N       N</span><br><span class="line">tensorflow_gpu-1.7.0       GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.9.0         7       9</span><br><span class="line">tensorflow-1.6.0           CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.9.0         N       N</span><br><span class="line">tensorflow_gpu-1.6.0       GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.9.0         7       9</span><br><span class="line">tensorflow-1.5.0           CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.8.0         N       N</span><br><span class="line">tensorflow_gpu-1.5.0       GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.8.0         7       9</span><br><span class="line">tensorflow-1.4.0           CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.5.4         N       N</span><br><span class="line">tensorflow_gpu-1.4.0       GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.5.4         6       8</span><br><span class="line">tensorflow-1.3.0           CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.4.5         N       N</span><br><span class="line">tensorflow_gpu-1.3.0       GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.4.5         6       8</span><br><span class="line">tensorflow-1.2.0           CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.4.5         N       N</span><br><span class="line">tensorflow_gpu-1.2.0       GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.4.5         5.1     8</span><br><span class="line">tensorflow-1.1.0           CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.4.2         N       N</span><br><span class="line">tensorflow_gpu-1.1.0       GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.4.2         5.1     8</span><br><span class="line">tensorflow-1.0.0           CPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.4.2         N       N</span><br><span class="line">tensorflow_gpu-1.0.0       GPU      2.7、3.3-3.6     GCC 4.8       Bazel 0.4.2         5.1     8</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Mac</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">TensorFlow 版本：     CPU/GPU:     Python 版本:      编译器:                 构建工具:      CUDNN:   CUDA:</span><br><span class="line">----------------------------------------------------------------------------------------------------------------------</span><br><span class="line">tensorflow-1.13.1      CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel 0.19.2        N       N</span><br><span class="line">tensorflow-1.12.0      CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel 0.15.1        N       N</span><br><span class="line">tensorflow-1.11.0      CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel 0.15.1        N       N</span><br><span class="line">tensorflow-1.10.0      CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel 0.15.1        N       N</span><br><span class="line">tensorflow-1.9.0       CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel 0.11.1        N       N</span><br><span class="line">tensorflow-1.8.0       CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel 0.10.1        N       N</span><br><span class="line">tensorflow-1.7.0       CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel 0.10.1        N       N</span><br><span class="line">tensorflow-1.6.0       CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel  0.8.1        N       N</span><br><span class="line">tensorflow-1.5.0       CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel  0.8.1        N       N</span><br><span class="line">tensorflow-1.4.0       CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel  0.5.4        N       N</span><br><span class="line">tensorflow-1.3.0       CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel  0.4.5        N       N</span><br><span class="line">tensorflow-1.2.0       CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel  0.4.5        N       N</span><br><span class="line"></span><br><span class="line">tensorflow-1.1.0       CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel  0.4.2        N       N</span><br><span class="line">tensorflow_gpu-1.1.0   GPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel  0.4.2        5.1     8</span><br><span class="line">tensorflow-1.0.0       CPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel  0.4.2        N       N</span><br><span class="line">tensorflow_gpu-1.0.0   GPU         2.7、3.3-3.6     XCode 中的 Clang      Bazel  0.4.2        5.1     8</span><br></pre></td></tr></table></figure>
<hr>

      
    </div>
    
    
    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">如果感觉文章对您有较大帮助，请随意打赏。您的鼓励是我保持持续创作的最大动力！</div>
    
</div>
      
    </div>

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div></div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/uploads/wechatpay.png" alt="TheMusicIsLoud 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/uploads/alipay.png" alt="TheMusicIsLoud 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    TheMusicIsLoud
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/" title="Ubuntu16.04 + Nvidia GTX 970 + CUDA8.0 + CUDNN5.1 + Anaconda3 + Tensorflow1.2">http://yoursite.com/TensorFlow/Ubuntu16-04-Nvidia-GTX-970-CUDA8-0-CUDNN5-1-Anaconda3-Tensorflow1-2/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/TensorFlow/" rel="tag"><i class="fa fa-tag"></i> TensorFlow</a>
          
            <a href="/tags/GPU/" rel="tag"><i class="fa fa-tag"></i> GPU</a>
          
            <a href="/tags/CUDA-CUDNN/" rel="tag"><i class="fa fa-tag"></i> CUDA&&CUDNN</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/TensorFlow/libstdc-so-6-version-CXXABI-1-3-X-not-found/" rel="next" title="libstdc++.so.6 version 'CXXABI_1.3.X' not found">
                <i class="fa fa-chevron-left"></i> libstdc++.so.6 version 'CXXABI_1.3.X' not found
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/DeepLearning-Paper/DeepLearning-Paper：ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/" rel="prev" title="DeepLearning Paper：ImageNet Classification with Deep Convolutional Neural Networks">
                DeepLearning Paper：ImageNet Classification with Deep Convolutional Neural Networks <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
<span class="jiathis_txt">分享到：</span>
<a class="jiathis_button_fav">收藏夹</a>
<a class="jiathis_button_copy">复制网址</a>
<a class="jiathis_button_email">邮件</a>
<a class="jiathis_button_weixin">微信</a>
<a class="jiathis_button_qzone">QQ空间</a>
<a class="jiathis_button_tqq">腾讯微博</a>
<a class="jiathis_button_douban">豆瓣</a>
<a class="jiathis_button_share">一键分享</a>

<a href="http://www.jiathis.com/share?uid=2140465" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a>
<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript">
var jiathis_config={
  data_track_clickback:true,
  summary:"",
  shortUrl:false,
  hideMore:false
}
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=" charset="utf-8"></script>
<!-- JiaThis Button END -->
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80MjA5OC8xODY0NQ=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/uploads/header.jpg" alt="TheMusicIsLoud">
            
              <p class="site-author-name" itemprop="name">TheMusicIsLoud</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">70</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">86</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/TheNightIsYoung" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://dev.tencent.com/" title="CloudStudio&&Coding" target="_blank">CloudStudio&&Coding</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Environmental-introduction"><span class="nav-text">Environmental introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Nvidia-GTX-970-安装显卡驱动"><span class="nav-text">1. Nvidia GTX 970 安装显卡驱动</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-查询-GPU-详细信息"><span class="nav-text">1.1 查询 GPU 详细信息</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-查询适合的-Nvidia-驱动"><span class="nav-text">1.2 查询适合的 Nvidia 驱动</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-安装-Nvidia-驱动"><span class="nav-text">1.3 安装 Nvidia 驱动</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-4-Nvidia-驱动卸载"><span class="nav-text">1.4 Nvidia 驱动卸载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-5-Want-to-know-more"><span class="nav-text">1.5 Want to know more</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-下载和安装-CUDA-8-0"><span class="nav-text">2. 下载和安装 CUDA 8.0</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-CUDA-下载"><span class="nav-text">2.1 CUDA 下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-CUDA-安装"><span class="nav-text">2.2 CUDA 安装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-CUDA-测试"><span class="nav-text">2.3 CUDA 测试</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-CUDA-卸载"><span class="nav-text">2.4 CUDA 卸载</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-CUDNN-5-1-安装"><span class="nav-text">3. CUDNN 5.1 安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-CUDNN-下载"><span class="nav-text">3.1 CUDNN 下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-CUDNN-安装"><span class="nav-text">3.2 CUDNN 安装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-CUDNN-升级"><span class="nav-text">3.3 CUDNN 升级</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Anaconda-Tensorflow-GPU-安装"><span class="nav-text">4. Anaconda + Tensorflow-GPU 安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-Conda-Envs-install-TensorFlow"><span class="nav-text">4.1 Conda Envs install TensorFlow</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-TensorFlow-导入测试"><span class="nav-text">4.2 TensorFlow 导入测试</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-GPU-运算测试"><span class="nav-text">4.3 GPU 运算测试</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-I-Want-To-Know-More"><span class="nav-text">5. I Want To Know More</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-NVIDIA-驱动相关"><span class="nav-text">5.1 NVIDIA 驱动相关</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-2-CUDA-多版本共存和实时切换"><span class="nav-text">5.2 CUDA 多版本共存和实时切换</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#5-2-1-CUDA-多版本共存"><span class="nav-text">5.2.1 CUDA 多版本共存</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#5-2-2-CUDA-版本实时切换"><span class="nav-text">5.2.2 CUDA 版本实时切换</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensorflow-amp-amp-NVIDIA-版本信息对照表"><span class="nav-text">Tensorflow &amp;&amp; NVIDIA 版本信息对照表</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#For-Windows"><span class="nav-text">For Windows</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#For-Linux-amp-amp-Mac"><span class="nav-text">For Linux &amp;&amp; Mac</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">TheMusicIsLoud</span>

  
</div>

<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>

-->


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info//busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      本站访客数<span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      本站总访问量<span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("L40cS1OTf2nXQmbIANou8HvS-gzGzoHsz", "t0xHBc4DURRDc9MDSKX7vx8c");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
